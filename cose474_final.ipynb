{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["h21bQ-ZG-REt","Aelz7c1jJJwI"],"gpuType":"T4","authorship_tag":"ABX9TyMKtv3VzJJTX4fZGu2wJ+UF"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["### setting"],"metadata":{"id":"QB5XanEG-UW2"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"P9ZsF12c9kfj","executionInfo":{"status":"ok","timestamp":1701616200520,"user_tz":-540,"elapsed":22636,"user":{"displayName":"이태후","userId":"03468433647806446322"}},"outputId":"e7731e8f-4fde-41bc-d3f2-4639840c8b7a"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["!pip install -q transformers"],"metadata":{"id":"wK2z5YI2kB8u","executionInfo":{"status":"ok","timestamp":1701616205640,"user_tz":-540,"elapsed":5125,"user":{"displayName":"이태후","userId":"03468433647806446322"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["cd '/content/drive/MyDrive/cose474_final/BioRAG'"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HEhHycAUSXRL","executionInfo":{"status":"ok","timestamp":1701617382258,"user_tz":-540,"elapsed":5,"user":{"displayName":"이태후","userId":"03468433647806446322"}},"outputId":"0f2e9113-223b-4351-ec1b-58bfa941887b"},"execution_count":36,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/cose474_final/BioRAG\n"]}]},{"cell_type":"code","source":["!ls"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RwgB2fE-TGiJ","executionInfo":{"status":"ok","timestamp":1701620310758,"user_tz":-540,"elapsed":545,"user":{"displayName":"이태후","userId":"03468433647806446322"}},"outputId":"895bfa1b-cbd7-4307-888d-7b452ecef05f"},"execution_count":41,"outputs":[{"output_type":"stream","name":"stdout","text":["bert_config.json  bioASQ-factoid  cose474_final.ipynb  qa_outputs  README.md  vocab.txt\n"]}]},{"cell_type":"code","source":["QA_DIR = './bioASQ-factoid'\n","OUTPUT_DIR = './qa_outputs'\n","TRAIN_FILE = './bioASQ-factoid/BioASQ-train-factoid-8b-full-annotated.json'\n","PREDICT_FILE = './bioASQ-factoid/BioASQ-test-factoid-8b-all.json'"],"metadata":{"id":"rMCJp5maTRuL","executionInfo":{"status":"ok","timestamp":1701618564541,"user_tz":-540,"elapsed":9,"user":{"displayName":"이태후","userId":"03468433647806446322"}}},"execution_count":39,"outputs":[]},{"cell_type":"markdown","source":["### tokenization"],"metadata":{"id":"h21bQ-ZG-REt"}},{"cell_type":"code","source":["# useful functions for data cleansing\n","\n","import unicodedata\n","\n","def decode_bytes(text):\n","\n","  '''check for bytes within text and decode them'''\n","\n","  if isinstance(text, str):\n","    return text\n","  elif isinstance(text, bytes):\n","    return text.decode(\"utf-8\", \"ignore\")\n","  else:\n","    raise ValueError(f\"unsupported string type: {text}\")\n","\n","def whitespace_tokenize(text):\n","\n","  '''strip text and split them'''\n","\n","  text = text.strip()\n","  if not text:\n","    return []\n","  tokens = text.split()\n","  return tokens\n","\n","def is_control(char):\n","\n","  ''' detect control characters except whitespace '''\n","\n","  if unicodedata.category(char).startswith('C'):\n","    if char == '\\t' or char == '\\n' or char == '\\r': # category starts with C but is whitespace\n","      return False\n","    return True\n","  else:\n","    return False\n","\n","def is_whitespace(char):\n","\n","  ''' check whether character is whitespace '''\n","\n","  if char == ' ' or char == '\\t' or char == '\\n' or char == '\\r':\n","    return True\n","  elif unicodedata.category(char) == \"Zs\": # \"space separator\" category\n","    return True\n","  else:\n","    return False\n","\n","def is_punc(char):\n","\n","  ''' check whether character is a punctuation '''\n","  # ~32 : 각종 공백문자, 48~57 : 숫자, 65~90 : 대문자 알파벳, 97~122 : 소문자 알파벳, 126~ : 이상한 기호들\n","  if (ord(char) >= 33 and ord(char) <= 47) or (ord(char) >= 58 and ord(char) <= 64):\n","    return True\n","  elif (ord(char) >= 91 and ord(char) <= 96) or (ord(char) > 123 and ord(char) <= 126):\n","    return True\n","  elif unicodedata.category(char).startswith(\"P\"): # punctuation\n","    return True\n","  else:\n","    return False"],"metadata":{"id":"_-a5ehob-M3v","executionInfo":{"status":"ok","timestamp":1701616205640,"user_tz":-540,"elapsed":7,"user":{"displayName":"이태후","userId":"03468433647806446322"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["import collections\n","\n","def load_vocab(vocab_file):\n","\n","  ''' load vocab file as dictionary '''\n","\n","  vocab_dict = collections.OrderedDict()\n","  idx=0\n","\n","  with open(vocab_file, \"r\") as rf:\n","    tokens = rf.read().splitlines()\n","\n","  for token in tokens:\n","    token = decode_bytes(token)\n","    token = token.strip()\n","    vocab_dict[token] = idx\n","    idx += 1\n","\n","  return vocab_dict"],"metadata":{"id":"EABAro7d37Ar","executionInfo":{"status":"ok","timestamp":1701616205640,"user_tz":-540,"elapsed":6,"user":{"displayName":"이태후","userId":"03468433647806446322"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["class BasicTokenizer(object):\n","  def __init__(self, do_lower_case=True):\n","    self.do_lower_case = do_lower_case\n","\n","  def clean_text(self, text):\n","\n","    ''' skip invalid characters, convert all whitespaces into single space, and return text '''\n","\n","    output = []\n","    for char in text:\n","      # check if char is NULL,�(unrecognizable), or control character\n","      if ord(char) == 0 or ord(char) == 65533 or is_control(char):\n","        continue\n","      if is_whitespace(char):\n","        output.append(\" \") # all whitespace -> \" \"\n","      else:\n","        output.append(char)\n","    return \"\".join(output)\n","\n","  def run_split_on_punc(self, text):\n","\n","    ''' split text based on punctuations '''\n","\n","    output = []\n","    token = ''\n","    for char in list(text):\n","      if is_punc(char):\n","        output.append(token)\n","        output.append(char)\n","        token = ''\n","      else:\n","        token += char\n","\n","    if len(token) > 0:\n","      output.append(token)\n","\n","    return output\n","\n","  def tokenize(self, text):\n","    text = decode_bytes(text)\n","    text = self.clean_text(text)\n","\n","    orig_tokens = whitespace_tokenize(text) # 공백문자 단위로 분리\n","    split_tokens = []\n","\n","    for token in orig_tokens: # 토큰별로 punctuation 있을 경우 분리\n","      if self.do_lower_case:\n","        token = token.lower()\n","      split_tokens.extend(self.run_split_on_punc(token))\n","\n","    return split_tokens"],"metadata":{"id":"qinZXvskH4a6","executionInfo":{"status":"ok","timestamp":1701616205641,"user_tz":-540,"elapsed":7,"user":{"displayName":"이태후","userId":"03468433647806446322"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["class WordpieceTokenizer(object):\n","  def __init__(self, vocab, unk_token=\"[UNK]\", max_input_chars_per_word=200):\n","    self.vocab = vocab\n","    self.unk_token = unk_token\n","    self.max_input_chars_per_word = max_input_chars_per_word\n","\n","  def tokenize(self, text):\n","    ''' input : a single token (via BasicTokenizer), output : wordpiece tokens\n","\n","    wordpiece merges characters by \"score = freq(pair) / freq(first)*freq(second)\".\n","    pairs that frequently appear together are merged, but not if each element also appears frequently\n","\n","    ex) unable : \"un\", \"##able\"\n","    ex) hugging : \"hugging\" '''\n","\n","    text = decode_bytes(text)\n","\n","    output_tokens = []\n","    for token in whitespace_tokenize(text):\n","      chars = list(token)\n","      # 너무 긴 단어 (>200)는 unk 처리\n","      if len(chars) > self.max_input_chars_per_word:\n","        output_tokens.append(self.unk_token)\n","        continue\n","\n","      is_bad = False\n","      start = 0\n","      sub_tokens = []\n","\n","      # ex. unfriendly : length 10\n","      while start < len(chars): # 0~9\n","        end = len(chars) # 10\n","        cur_substr = None\n","        while start < end:\n","          substr = \"\".join(chars[start:end]) # unfriendly, unfriendl, unfriend, ... , un\n","          if start > 0:\n","            substr = \"##\" + substr # indicates subword\n","          if substr in self.vocab: # \"unfriendly\" not in vocab / ... \"un\" in vocab\n","            cur_substr = substr\n","            break\n","          end -= 1\n","        if cur_substr is None:\n","          is_bad = True\n","          break\n","        sub_tokens.append(cur_substr)\n","\n","        start = end # subword 떨어져나간 경우 (un) 끝자리->시작자리 (f)\n","\n","      if is_bad: # character 한개도 vocab에 없는 경우\n","        output_tokens.append(self.unk_token)\n","      else:\n","        output_tokens.extend(sub_tokens)\n","\n","    return output_tokens\n","\n"],"metadata":{"id":"1kgEsgaQnrCa","executionInfo":{"status":"ok","timestamp":1701616205641,"user_tz":-540,"elapsed":7,"user":{"displayName":"이태후","userId":"03468433647806446322"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["class FullTokenizer(object):\n","  def __init__(self, vocab_file, do_lower_case=True):\n","    self.vocab = load_vocab(vocab_file)\n","    self.vocab_reverse = {v:k for k,v in self.vocab.items()}\n","    self.basic_tokenizer = BasicTokenizer(do_lower_case=do_lower_case)\n","    self.wordpiece = WordpieceTokenizer(vocab=self.vocab)\n","\n","  def tokenize(self, text):\n","    split_tokens = []\n","    for token in self.basic_tokenizer.tokenize(text): # cleanse text, tokenize by punctuation\n","      for sub_token in self.wordpiece.tokenize(token): # tokenize tokens (subtokens)\n","        split_tokens.append(sub_token)\n","\n","    return split_tokens\n","\n","  def convert_tokens_to_ids(self, tokens):\n","    output = []\n","    for token in tokens:\n","      output.append(self.vocab[token])\n","    return output"],"metadata":{"id":"E9y_UXkh3yQC","executionInfo":{"status":"ok","timestamp":1701616205641,"user_tz":-540,"elapsed":7,"user":{"displayName":"이태후","userId":"03468433647806446322"}}},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":["### data processing"],"metadata":{"id":"BJBzS902_U93"}},{"cell_type":"code","source":["from absl import flags\n","\n","flags.DEFINE_string(\"bert_config_file\", \"./bert_config.json\", \"config json file corresponding to the pretrained BERT model\")\n","flags.DEFINE_string(\"vocab_file\", \"./vocab.txt\", \"vocab file on which BERT was trained\")\n","flags.DEFINE_string(\"output_dir\", OUTPUT_DIR, \"output dir for model checkpoints\")\n","flags.DEFINE_string(\"train_file\", TRAIN_FILE, \"squad-formatted json for training. E.g., train-v1.1.json\")\n","flags.DEFINE_string(\"predict_file\", PREDICT_FILE, \"squad-formatted json for predictions. E.g., dev(test)-v1.1.json\")\n","flags.DEFINE_string(\"init_checkpoint\", None, \"initial checkpoint (usually from a pretrained BERT model)\")\n","\n","flags.DEFINE_bool(\"do_lower_case\", True, \"whether to lower-case input text. True for lower case.\")\n","flags.DEFINE_bool(\"do_train\", True, \"whether to run training\")\n","flags.DEFINE_bool(\"do_predict\", True, \"whether to run eval on the dev set\")\n","flags.DEFINE_bool(\"verbose_logging\", False, \"whether to print all warnings during data processing. Other warnings are printed by default.\")\n","\n","flags.DEFINE_integer(\"max_seq_len\", 384, \"maximum input sequence after WordPiece tokenization. Will be padded if shorter, truncated if longer.\")\n","flags.DEFINE_integer(\"doc_stride\", 128, \"when splitting up a long document into chunks, how much stride to take between chunks\")\n","flags.DEFINE_integer(\"max_query_len\", 64, \"maximum query sequence after WordPiece tokenization. Will be truncated if longer.\")\n","flags.DEFINE_integer(\"predict_batch_size\", 8, \"total batch size for predictions\")\n","flags.DEFINE_integer(\"save_checkpoint_step\", 1000, \"how often to save model checkpoints\")\n","flags.DEFINE_integer(\"iterations_per_loop\", 1000, \"how many steps to make in each estimator call\")\n","flags.DEFINE_integer(\"n_best_size\", 20, \"how many n-best predictions to generate in nbest_predictions.json output file\")\n","flags.DEFINE_integer(\"max_answer_len\", 30, \"maximum length of generated answer\")\n","\n","flags.DEFINE_float(\"learning_rate\", 5e-5, \"initial learning rate for Adam optimizer\")\n","flags.DEFINE_float(\"num_train_epochs\", 3.0, \"number of training epochs\")\n","flags.DEFINE_float(\"warmup_proportion\", 0.1, \"proportion of training for linear lr warmup. E.g., 0.1 refers to 10% of training\")\n","flags.DEFINE_float(\"null_score_diff_threshold\", 0.0, \"to predict null if (null_score - best_non_null) > threshold\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"M6iOQ_ARlZpZ","executionInfo":{"status":"ok","timestamp":1701616904062,"user_tz":-540,"elapsed":491,"user":{"displayName":"이태후","userId":"03468433647806446322"}},"outputId":"766bd054-b28d-427d-d4ff-9e306aece02b"},"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<absl.flags._flagvalues.FlagHolder at 0x7fb1e2c49ba0>"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["class SquadExample(object):\n","  def __init__(self, qas_id, question_text, doc_tokens, origin_answer_text=None, start_pos=None, end_pos=None):\n","    self.qas_id = qas_id\n","    self.question_text = question_text\n","    self.doc_tokens = doc_tokens\n","    self.origin_answer_text = origin_answer_text\n","    self.start_pos = start_pos\n","    self.end_pos = end_pos\n","\n","  def __str__(self):\n","    return self.__repr__()\n","\n","  def __repr__(self):\n","    s = f\"qas_id: {decode_bytes(self.qas_id)}\" # check if text is in str, bytes or unicode and convert\n","    s += f\", question_text: {decode_bytes(self.question_text)}\"\n","    s += f\", doc_tokens: {[' '.join(self.doc_tokens)]}\"\n","\n","    if self.start_pos:\n","      s += f\", start_pos: {self.start_pos}, end_pos: {self.end_pos}\"\n","\n","    return s\n"],"metadata":{"id":"CAu4TqjuvWVJ","executionInfo":{"status":"ok","timestamp":1701616905494,"user_tz":-540,"elapsed":565,"user":{"displayName":"이태후","userId":"03468433647806446322"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["import json\n","\n","def read_squad_examples(input_file, is_training):\n","  \"\"\"Read a squad json file into a list of SquadExample\"\"\"\n","\n","  with open(input_file, \"r\") as rf:\n","    input_data = json.load(rf)[\"data\"][0][\"paragraphs\"]\n","\n","  examples = []\n","  for entry in input_data:\n","    doc_tokens = []\n","    char_to_word_offset = []\n","    prev_is_whitespace = True\n","\n","    context = entry[\"context\"]\n","    for c in context:\n","      if is_whitespace(c):\n","        prev_is_whitespace=True\n","      else:\n","        if prev_is_whitespace: # c comes after whitespace -> add as new token\n","          doc_tokens.append(c)\n","        else:\n","          doc_tokens[-1] += c # c comes after c -> attach to recent token\n","        prev_is_whitespace=False\n","      char_to_word_offset.append(len(doc_tokens) -1) # \"I went home\" -> [0,0,1,1,1,1,1,2,2,2,2]\n","\n","    qas = entry[\"qas\"]\n","    for qa in qas:\n","      qas_id = qa[\"id\"]\n","      question_text = qa[\"question\"]\n","      start_pos = None\n","      end_pos = None\n","      origin_answer_text = None\n","\n","      if is_training:\n","        if len(qa[\"answers\"]) != 1:\n","          raise ValueError(\"Each question should have exactly 1 answer.\")\n","\n","        answer = qa[\"answers\"][0]\n","        origin_answer_text = answer[\"text\"] #\"Bazex syndrome\"\n","        answer_offset = answer[\"answer_start\"] #93\n","        answer_length = len(origin_answer_text)\n","        start_pos = char_to_word_offset[answer_offset] # 몇번째 단어부터\n","        end_pos = char_to_word_offset[answer_offset + answer_length-1] # 몇번째 단어까지\n","\n","        # check if answer text is extractable from context (아닌 경우 건너뜀)\n","        answer_from_context = \" \".join(doc_tokens[start_pos:end_pos+1]) # context에서 주어진 범위로 인덱싱한 정답\n","        cleaned_answer = \" \".join(whitespace_tokenize(origin_answer_text)) # 실제 정답 (strip 및 split)\n","\n","        if answer_from_context.find(cleaned_answer) == -1: # context에 정답이 들어있지 않은 경우\n","          tf.logging.warning(f\"Could not find answer from context. {answer_from_context} vs {cleaned_answer}\")\n","          continue\n","\n","      else: # inference용\n","        start_pos = -1\n","        end_pos = -1\n","        origin_answer_text = \"\"\n","\n","      example = SquadExample(qas_id=qas_id, question_text=question_text, doc_tokens=doc_tokens,\n","                              origin_answer_text=origin_answer_text, start_pos=start_pos, end_pos=end_pos)\n","      examples.append(example)\n","\n","  return examples"],"metadata":{"id":"Jb-H6ed4BC7Q","executionInfo":{"status":"ok","timestamp":1701616905494,"user_tz":-540,"elapsed":2,"user":{"displayName":"이태후","userId":"03468433647806446322"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["examples = read_squad_examples('/content/drive/MyDrive/cose474_final/trainset_bioasq.json', is_training=True)"],"metadata":{"id":"N2Pa84IpUCGT","executionInfo":{"status":"ok","timestamp":1701616919349,"user_tz":-540,"elapsed":13856,"user":{"displayName":"이태후","userId":"03468433647806446322"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["len(examples)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tI5bmUTNwD6E","executionInfo":{"status":"ok","timestamp":1701616919349,"user_tz":-540,"elapsed":8,"user":{"displayName":"이태후","userId":"03468433647806446322"}},"outputId":"90f7d5fc-cce9-4697-f804-5892f0889f54"},"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["11171"]},"metadata":{},"execution_count":13}]},{"cell_type":"code","source":["def check_is_max_context(doc_spans, cur_span_idx, pos):\n","  '''check whether a span gives maximum \"score\" for a token.\n","  ex) Span A: the man went to the\n","  Span B: to the store and bought\n","  Span C: and bought a gallon of\n","\n","  \"bought\" will have 2 scores from span B and C.\n","  we choose span with maximum context, which is defined as min(left, right).\n","  Span B : min(4,0) = 0\n","  Span C : min(1,3) = 1\n","\n","  We choose Span C as the maximum context for the token \"bought\".'''\n","\n","  best_score = None\n","  best_span_idx = None\n","\n","  for idx, doc_span in enumerate(doc_spans):\n","    end = doc_span.start + doc_span.length - 1\n","    if pos < doc_span.start:\n","      continue\n","    if pos > end:\n","      continue\n","    num_left_context = pos - doc_span.start\n","    num_right_context = end - pos\n","    score = min(num_left_context, num_right_context) + 0.01*doc_span.length\n","    if best_score is None or score > best_score:\n","      best_score = score\n","      best_span_idx = idx\n","\n","  return cur_span_idx == best_span_idx"],"metadata":{"id":"4bb0IhsYpDNr","executionInfo":{"status":"ok","timestamp":1701616919349,"user_tz":-540,"elapsed":5,"user":{"displayName":"이태후","userId":"03468433647806446322"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["import json\n","import tensorflow as tf\n","\n","class InputFeatures(object):\n","  def __init__(self, unique_id, example_index, doc_span_index, tokens, token_to_origin_map, token_is_max_context,\n","             input_ids, input_mask, segment_ids, start_pos=None, end_pos=None):\n","    self.unique_id = unique_id\n","    self.example_index = example_index\n","    self.doc_span_index = doc_span_index\n","    self.tokens = tokens\n","    self.token_to_origin_map = token_to_origin_map\n","    self.token_is_max_context = token_is_max_context\n","    self.input_ids = input_ids\n","    self.input_mask = input_mask\n","    self.segment_ids = segment_ids\n","    self.start_pos = start_pos\n","    self.end_pos = end_pos"],"metadata":{"id":"mIS-ohuH7TiL","executionInfo":{"status":"ok","timestamp":1701616922830,"user_tz":-540,"elapsed":3485,"user":{"displayName":"이태후","userId":"03468433647806446322"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["def convert_examples_to_features(examples, tokenizer, max_seq_len, doc_stride, max_query_len, is_training, output_fn):\n","  unique_id = 1000000000\n","\n","  for example_idx, example in enumerate(examples):\n","    query_tokens = tokenizer.tokenize(example.question_text)\n","\n","    if len(query_tokens) > max_query_len:\n","      query_tokens = query_tokens[:max_query_len] # query 최대 길이로 제한\n","\n","    word_to_subtoken_idx = [] # 각 단어가 subtoken 기준으로 몇번째인지 (ex. 3번째 단어 -> 9번째 subword부터)\n","    subtoken_to_word_idx = [] # 각 subtoken이 원래 몇번째 단어에 속하는지 (ex. 9번째 subword -> 3번째 단어)\n","    all_doc_tokens = [] # 모든 subtoken 모음\n","\n","    for i, token in enumerate(example.doc_tokens): # Psoriasiform, dermatitis, in, a, case, ...\n","      word_to_subtoken_idx.append(len(all_doc_tokens))\n","      sub_tokens = tokenizer.tokenize(token) # tokenize into subwords\n","      for sub_token in sub_tokens:\n","        subtoken_to_word_idx.append(i)\n","        all_doc_tokens.append(sub_token)\n","\n","    tok_start_pos = None\n","    tok_end_pos = None\n","\n","    print(f'all_doc_tokens : {all_doc_tokens}')\n","    print(f'word_to_subtoken_idx : {word_to_subtoken_idx}')\n","    print(f'subtoken_to_word_idx : {subtoken_to_word_idx}')\n","\n","    if is_training:\n","      tok_start_pos = word_to_subtoken_idx[example.start_pos]\n","      if example.end_pos < len(example.doc_tokens) - 1:\n","        tok_end_pos = word_to_subtoken_idx[example.end_pos + 1] - 1\n","      else: # 범위 벗어난 경우\n","        tok_end_pos = len(all_doc_tokens) - 1\n","\n","    print(f'tok_start_pos : {tok_start_pos}')\n","    print(f'tok_end_pos : {tok_end_pos}')\n","    print(f'answer tokens : {all_doc_tokens[tok_start_pos:tok_end_pos+1]}')\n","\n","    # max_seq_len = len(query_tokens) + len(doc_tokens) + 3 ([CLS], [SEP], [SEP] : 문장 시작, 문장 구분, 문장 끝)\n","    max_tokens_for_doc = max_seq_len - len(query_tokens) - 3 # (384-11-3) = 370\n","\n","    # sliding window for long document training\n","    Docspan = collections.namedtuple('Docspan', ['start', 'length'])\n","    doc_spans = []\n","    start = 0 # 0 -> 128 -> 256 -> 384\n","    while start < len(all_doc_tokens):\n","      length = len(all_doc_tokens) - start # 729 -> 601 -> 473 -> 345\n","      if length > max_tokens_for_doc:\n","        length = max_tokens_for_doc\n","      doc_spans.append(Docspan(start=start, length=length))\n","      if start + length == len(all_doc_tokens): # 384 + 345 = 729\n","        break\n","      start += min(length, doc_stride)\n","    print(doc_spans)\n","\n","    for doc_span_idx, doc_span in enumerate(doc_spans):\n","      tokens = []\n","      token_to_orig_map = {}\n","      token_is_max_context = {}\n","      segment_ids = [] # [cls]query[sep] / doc[sep] : 00000/11111 로 구분\n","\n","      tokens.append(\"[CLS]\")\n","      segment_ids.append(0)\n","\n","      for token in query_tokens:\n","        tokens.append(token)\n","        segment_ids.append(0)\n","      tokens.append(\"[SEP]\")\n","      segment_ids.append(0)\n","\n","      for i in range(doc_span.length):\n","        doc_idx = doc_span.start + i\n","        token_to_orig_map[len(tokens)] = subtoken_to_word_idx[doc_idx]\n","\n","        is_max_context = check_is_max_context(doc_spans, doc_span_idx, doc_idx)\n","        token_is_max_context[len(tokens)] = is_max_context\n","        tokens.append(all_doc_tokens[doc_idx])\n","        segment_ids.append(1)\n","\n","      tokens.append(\"[SEP]\")\n","      segment_ids.append(1)\n","\n","      # encode tokens to ids (index numbers of vocabs)\n","      input_ids = tokenizer.convert_tokens_to_ids(tokens)\n","\n","      # masking (1 for real tokens, 0 for padding tokens)\n","      input_mask = [1] * len(input_ids)\n","      while len(input_ids) < max_seq_len:\n","        input_ids.append(0)\n","        input_mask.append(0)\n","        segment_ids.append(0)\n","\n","      assert len(input_ids) == max_seq_len\n","      assert len(input_mask) == max_seq_len\n","      assert len(segment_ids) == max_seq_len\n","\n","      start_pos = None\n","      end_pos = None\n","\n","      if is_training:\n","        doc_start = doc_span.start\n","        doc_end = doc_span.start + doc_span.length - 1\n","        out_of_span = False\n","\n","        if not (tok_start_pos >= doc_start and tok_end_pos <= doc_end): # tok_start_pos : word_to_subtoken_idx[example.start_pos]\n","          out_of_span = True\n","        if out_of_span:\n","          start_pos = 0\n","          end_pos = 0\n","        else:\n","          doc_offset = len(query_tokens) + 2\n","          start_pos = tok_start_pos - doc_start + doc_offset\n","          end_pos = tok_end_pos - doc_start + doc_offset\n","\n","      ##############################################################################################################\n","\n","      feature = InputFeatures(\n","          unique_id=unique_id,\n","          example_index=example_idx,\n","          doc_span_index=doc_span_idx,\n","          tokens=tokens,\n","          token_to_origin_map=token_to_orig_map,\n","          token_is_max_context=token_is_max_context,\n","          input_ids=input_ids,\n","          input_mask=input_mask,\n","          segment_ids=segment_ids,\n","          start_pos=start_pos,\n","          end_pos=end_pos\n","      )\n","      output_fn(feature)\n","\n","      unique_id += 1\n"],"metadata":{"id":"fOOxoauhVffT","executionInfo":{"status":"ok","timestamp":1701616922830,"user_tz":-540,"elapsed":13,"user":{"displayName":"이태후","userId":"03468433647806446322"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["def improve_answer_span(doc_tokens, input_start, input_end, tokenizer, orig_answer_text):\n","  tok_answer_text = \" \".join(tokenizer.tokenize(orig_answer_text)) # ( 1895 - 1943 )\n","\n","  for new_start in range(input_start, input_end+1):\n","    for new_end in range(input_end, new_start -l, -1):\n","      text_span = \" \".join(doc_tokens[new_start:(new_end + 1)])\n","      if text_span == tok_answer_text:\n","        return (new_start, new_end)\n","\n","  return (input_start, input_end)"],"metadata":{"id":"cibVJNrmUDfZ","executionInfo":{"status":"ok","timestamp":1701616922830,"user_tz":-540,"elapsed":12,"user":{"displayName":"이태후","userId":"03468433647806446322"}}},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":["### BERT (copyright : Google AI Language Team Authors)"],"metadata":{"id":"odh-6SyJXlZp"}},{"cell_type":"code","source":["# coding=utf-8\n","# Copyright 2018 The Google AI Language Team Authors.\n","#\n","# Licensed under the Apache License, Version 2.0 (the \"License\");\n","# you may not use this file except in compliance with the License.\n","# You may obtain a copy of the License at\n","#\n","#     http://www.apache.org/licenses/LICENSE-2.0\n","#\n","# Unless required by applicable law or agreed to in writing, software\n","# distributed under the License is distributed on an \"AS IS\" BASIS,\n","# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","# See the License for the specific language governing permissions and\n","# limitations under the License.\n","\"\"\"The main BERT model and related functions.\"\"\"\n","\n","from __future__ import absolute_import\n","from __future__ import division\n","from __future__ import print_function\n","\n","import collections\n","import copy\n","import json\n","import math\n","import re\n","import six\n","import tensorflow as tf\n","\n","\n","class BertConfig(object):\n","  \"\"\"Configuration for `BertModel`.\"\"\"\n","\n","  def __init__(self,\n","               vocab_size,\n","               hidden_size=768,\n","               num_hidden_layers=12,\n","               num_attention_heads=12,\n","               intermediate_size=3072,\n","               hidden_act=\"gelu\",\n","               hidden_dropout_prob=0.1,\n","               attention_probs_dropout_prob=0.1,\n","               max_position_embeddings=512,\n","               type_vocab_size=16,\n","               initializer_range=0.02):\n","    \"\"\"Constructs BertConfig.\n","\n","    Args:\n","      vocab_size: Vocabulary size of `inputs_ids` in `BertModel`.\n","      hidden_size: Size of the encoder layers and the pooler layer.\n","      num_hidden_layers: Number of hidden layers in the Transformer encoder.\n","      num_attention_heads: Number of attention heads for each attention layer in\n","        the Transformer encoder.\n","      intermediate_size: The size of the \"intermediate\" (i.e., feed-forward)\n","        layer in the Transformer encoder.\n","      hidden_act: The non-linear activation function (function or string) in the\n","        encoder and pooler.\n","      hidden_dropout_prob: The dropout probability for all fully connected\n","        layers in the embeddings, encoder, and pooler.\n","      attention_probs_dropout_prob: The dropout ratio for the attention\n","        probabilities.\n","      max_position_embeddings: The maximum sequence length that this model might\n","        ever be used with. Typically set this to something large just in case\n","        (e.g., 512 or 1024 or 2048).\n","      type_vocab_size: The vocabulary size of the `token_type_ids` passed into\n","        `BertModel`.\n","      initializer_range: The stdev of the truncated_normal_initializer for\n","        initializing all weight matrices.\n","    \"\"\"\n","    self.vocab_size = vocab_size\n","    self.hidden_size = hidden_size\n","    self.num_hidden_layers = num_hidden_layers\n","    self.num_attention_heads = num_attention_heads\n","    self.hidden_act = hidden_act\n","    self.intermediate_size = intermediate_size\n","    self.hidden_dropout_prob = hidden_dropout_prob\n","    self.attention_probs_dropout_prob = attention_probs_dropout_prob\n","    self.max_position_embeddings = max_position_embeddings\n","    self.type_vocab_size = type_vocab_size\n","    self.initializer_range = initializer_range\n","\n","  @classmethod\n","  def from_dict(cls, json_object):\n","    \"\"\"Constructs a `BertConfig` from a Python dictionary of parameters.\"\"\"\n","    config = BertConfig(vocab_size=None)\n","    for (key, value) in six.iteritems(json_object):\n","      config.__dict__[key] = value\n","    return config\n","\n","  @classmethod\n","  def from_json_file(cls, json_file):\n","    \"\"\"Constructs a `BertConfig` from a json file of parameters.\"\"\"\n","    with tf.gfile.GFile(json_file, \"r\") as reader:\n","      text = reader.read()\n","    return cls.from_dict(json.loads(text))\n","\n","  def to_dict(self):\n","    \"\"\"Serializes this instance to a Python dictionary.\"\"\"\n","    output = copy.deepcopy(self.__dict__)\n","    return output\n","\n","  def to_json_string(self):\n","    \"\"\"Serializes this instance to a JSON string.\"\"\"\n","    return json.dumps(self.to_dict(), indent=2, sort_keys=True) + \"\\n\"\n","\n","\n","class BertModel(object):\n","  \"\"\"BERT model (\"Bidirectional Encoder Representations from Transformers\").\n","\n","  Example usage:\n","\n","  ```python\n","  # Already been converted into WordPiece token ids\n","  input_ids = tf.constant([[31, 51, 99], [15, 5, 0]])\n","  input_mask = tf.constant([[1, 1, 1], [1, 1, 0]])\n","  token_type_ids = tf.constant([[0, 0, 1], [0, 2, 0]])\n","\n","  config = modeling.BertConfig(vocab_size=32000, hidden_size=512,\n","    num_hidden_layers=8, num_attention_heads=6, intermediate_size=1024)\n","\n","  model = modeling.BertModel(config=config, is_training=True,\n","    input_ids=input_ids, input_mask=input_mask, token_type_ids=token_type_ids)\n","\n","  label_embeddings = tf.get_variable(...)\n","  pooled_output = model.get_pooled_output()\n","  logits = tf.matmul(pooled_output, label_embeddings)\n","  ...\n","  ```\n","  \"\"\"\n","\n","  def __init__(self,\n","               config,\n","               is_training,\n","               input_ids,\n","               input_mask=None,\n","               token_type_ids=None,\n","               use_one_hot_embeddings=True,\n","               scope=None):\n","    \"\"\"Constructor for BertModel.\n","\n","    Args:\n","      config: `BertConfig` instance.\n","      is_training: bool. true for training model, false for eval model. Controls\n","        whether dropout will be applied.\n","      input_ids: int32 Tensor of shape [batch_size, seq_length].\n","      input_mask: (optional) int32 Tensor of shape [batch_size, seq_length].\n","      token_type_ids: (optional) int32 Tensor of shape [batch_size, seq_length].\n","      use_one_hot_embeddings: (optional) bool. Whether to use one-hot word\n","        embeddings or tf.embedding_lookup() for the word embeddings. On the TPU,\n","        it is much faster if this is True, on the CPU or GPU, it is faster if\n","        this is False.\n","      scope: (optional) variable scope. Defaults to \"bert\".\n","\n","    Raises:\n","      ValueError: The config is invalid or one of the input tensor shapes\n","        is invalid.\n","    \"\"\"\n","    config = copy.deepcopy(config)\n","    if not is_training:\n","      config.hidden_dropout_prob = 0.0\n","      config.attention_probs_dropout_prob = 0.0\n","\n","    input_shape = get_shape_list(input_ids, expected_rank=2)\n","    batch_size = input_shape[0]\n","    seq_length = input_shape[1]\n","\n","    if input_mask is None:\n","      input_mask = tf.ones(shape=[batch_size, seq_length], dtype=tf.int32)\n","\n","    if token_type_ids is None:\n","      token_type_ids = tf.zeros(shape=[batch_size, seq_length], dtype=tf.int32)\n","\n","    with tf.variable_scope(scope, default_name=\"bert\"):\n","      with tf.variable_scope(\"embeddings\"):\n","        # Perform embedding lookup on the word ids.\n","        (self.embedding_output, self.embedding_table) = embedding_lookup(\n","            input_ids=input_ids,\n","            vocab_size=config.vocab_size,\n","            embedding_size=config.hidden_size,\n","            initializer_range=config.initializer_range,\n","            word_embedding_name=\"word_embeddings\",\n","            use_one_hot_embeddings=use_one_hot_embeddings)\n","\n","        # Add positional embeddings and token type embeddings, then layer\n","        # normalize and perform dropout.\n","        self.embedding_output = embedding_postprocessor(\n","            input_tensor=self.embedding_output,\n","            use_token_type=True,\n","            token_type_ids=token_type_ids,\n","            token_type_vocab_size=config.type_vocab_size,\n","            token_type_embedding_name=\"token_type_embeddings\",\n","            use_position_embeddings=True,\n","            position_embedding_name=\"position_embeddings\",\n","            initializer_range=config.initializer_range,\n","            max_position_embeddings=config.max_position_embeddings,\n","            dropout_prob=config.hidden_dropout_prob)\n","\n","      with tf.variable_scope(\"encoder\"):\n","        # This converts a 2D mask of shape [batch_size, seq_length] to a 3D\n","        # mask of shape [batch_size, seq_length, seq_length] which is used\n","        # for the attention scores.\n","        attention_mask = create_attention_mask_from_input_mask(\n","            input_ids, input_mask)\n","\n","        # Run the stacked transformer.\n","        # `sequence_output` shape = [batch_size, seq_length, hidden_size].\n","        self.all_encoder_layers = transformer_model(\n","            input_tensor=self.embedding_output,\n","            attention_mask=attention_mask,\n","            hidden_size=config.hidden_size,\n","            num_hidden_layers=config.num_hidden_layers,\n","            num_attention_heads=config.num_attention_heads,\n","            intermediate_size=config.intermediate_size,\n","            intermediate_act_fn=get_activation(config.hidden_act),\n","            hidden_dropout_prob=config.hidden_dropout_prob,\n","            attention_probs_dropout_prob=config.attention_probs_dropout_prob,\n","            initializer_range=config.initializer_range,\n","            do_return_all_layers=True)\n","\n","      self.sequence_output = self.all_encoder_layers[-1]\n","      # The \"pooler\" converts the encoded sequence tensor of shape\n","      # [batch_size, seq_length, hidden_size] to a tensor of shape\n","      # [batch_size, hidden_size]. This is necessary for segment-level\n","      # (or segment-pair-level) classification tasks where we need a fixed\n","      # dimensional representation of the segment.\n","      with tf.variable_scope(\"pooler\"):\n","        # We \"pool\" the model by simply taking the hidden state corresponding\n","        # to the first token. We assume that this has been pre-trained\n","        first_token_tensor = tf.squeeze(self.sequence_output[:, 0:1, :], axis=1)\n","        self.pooled_output = tf.layers.dense(\n","            first_token_tensor,\n","            config.hidden_size,\n","            activation=tf.tanh,\n","            kernel_initializer=create_initializer(config.initializer_range))\n","\n","  def get_pooled_output(self):\n","    return self.pooled_output\n","\n","  def get_sequence_output(self):\n","    \"\"\"Gets final hidden layer of encoder.\n","\n","    Returns:\n","      float Tensor of shape [batch_size, seq_length, hidden_size] corresponding\n","      to the final hidden of the transformer encoder.\n","    \"\"\"\n","    return self.sequence_output\n","\n","  def get_all_encoder_layers(self):\n","    return self.all_encoder_layers\n","\n","  def get_embedding_output(self):\n","    \"\"\"Gets output of the embedding lookup (i.e., input to the transformer).\n","\n","    Returns:\n","      float Tensor of shape [batch_size, seq_length, hidden_size] corresponding\n","      to the output of the embedding layer, after summing the word\n","      embeddings with the positional embeddings and the token type embeddings,\n","      then performing layer normalization. This is the input to the transformer.\n","    \"\"\"\n","    return self.embedding_output\n","\n","  def get_embedding_table(self):\n","    return self.embedding_table\n","\n","\n","def gelu(input_tensor):\n","  \"\"\"Gaussian Error Linear Unit.\n","\n","  This is a smoother version of the RELU.\n","  Original paper: https://arxiv.org/abs/1606.08415\n","\n","  Args:\n","    input_tensor: float Tensor to perform activation.\n","\n","  Returns:\n","    `input_tensor` with the GELU activation applied.\n","  \"\"\"\n","  cdf = 0.5 * (1.0 + tf.erf(input_tensor / tf.sqrt(2.0)))\n","  return input_tensor * cdf\n","\n","\n","def get_activation(activation_string):\n","  \"\"\"Maps a string to a Python function, e.g., \"relu\" => `tf.nn.relu`.\n","\n","  Args:\n","    activation_string: String name of the activation function.\n","\n","  Returns:\n","    A Python function corresponding to the activation function. If\n","    `activation_string` is None, empty, or \"linear\", this will return None.\n","    If `activation_string` is not a string, it will return `activation_string`.\n","\n","  Raises:\n","    ValueError: The `activation_string` does not correspond to a known\n","      activation.\n","  \"\"\"\n","\n","  # We assume that anything that\"s not a string is already an activation\n","  # function, so we just return it.\n","  if not isinstance(activation_string, six.string_types):\n","    return activation_string\n","\n","  if not activation_string:\n","    return None\n","\n","  act = activation_string.lower()\n","  if act == \"linear\":\n","    return None\n","  elif act == \"relu\":\n","    return tf.nn.relu\n","  elif act == \"gelu\":\n","    return gelu\n","  elif act == \"tanh\":\n","    return tf.tanh\n","  else:\n","    raise ValueError(\"Unsupported activation: %s\" % act)\n","\n","\n","def get_assignment_map_from_checkpoint(tvars, init_checkpoint):\n","  \"\"\"Compute the union of the current variables and checkpoint variables.\"\"\"\n","  assignment_map = {}\n","  initialized_variable_names = {}\n","\n","  name_to_variable = collections.OrderedDict()\n","  for var in tvars:\n","    name = var.name\n","    m = re.match(\"^(.*):\\\\d+$\", name)\n","    if m is not None:\n","      name = m.group(1)\n","    name_to_variable[name] = var\n","\n","  init_vars = tf.train.list_variables(init_checkpoint)\n","\n","  assignment_map = collections.OrderedDict()\n","  for x in init_vars:\n","    (name, var) = (x[0], x[1])\n","    if name not in name_to_variable:\n","      continue\n","    assignment_map[name] = name\n","    initialized_variable_names[name] = 1\n","    initialized_variable_names[name + \":0\"] = 1\n","\n","  return (assignment_map, initialized_variable_names)\n","\n","\n","def dropout(input_tensor, dropout_prob):\n","  \"\"\"Perform dropout.\n","\n","  Args:\n","    input_tensor: float Tensor.\n","    dropout_prob: Python float. The probability of dropping out a value (NOT of\n","      *keeping* a dimension as in `tf.nn.dropout`).\n","\n","  Returns:\n","    A version of `input_tensor` with dropout applied.\n","  \"\"\"\n","  if dropout_prob is None or dropout_prob == 0.0:\n","    return input_tensor\n","\n","  output = tf.nn.dropout(input_tensor, 1.0 - dropout_prob)\n","  return output\n","\n","\n","def layer_norm(input_tensor, name=None):\n","  \"\"\"Run layer normalization on the last dimension of the tensor.\"\"\"\n","  return tf.contrib.layers.layer_norm(\n","      inputs=input_tensor, begin_norm_axis=-1, begin_params_axis=-1, scope=name)\n","\n","\n","def layer_norm_and_dropout(input_tensor, dropout_prob, name=None):\n","  \"\"\"Runs layer normalization followed by dropout.\"\"\"\n","  output_tensor = layer_norm(input_tensor, name)\n","  output_tensor = dropout(output_tensor, dropout_prob)\n","  return output_tensor\n","\n","\n","def create_initializer(initializer_range=0.02):\n","  \"\"\"Creates a `truncated_normal_initializer` with the given range.\"\"\"\n","  return tf.truncated_normal_initializer(stddev=initializer_range)\n","\n","\n","def embedding_lookup(input_ids,\n","                     vocab_size,\n","                     embedding_size=128,\n","                     initializer_range=0.02,\n","                     word_embedding_name=\"word_embeddings\",\n","                     use_one_hot_embeddings=False):\n","  \"\"\"Looks up words embeddings for id tensor.\n","\n","  Args:\n","    input_ids: int32 Tensor of shape [batch_size, seq_length] containing word\n","      ids.\n","    vocab_size: int. Size of the embedding vocabulary.\n","    embedding_size: int. Width of the word embeddings.\n","    initializer_range: float. Embedding initialization range.\n","    word_embedding_name: string. Name of the embedding table.\n","    use_one_hot_embeddings: bool. If True, use one-hot method for word\n","      embeddings. If False, use `tf.nn.embedding_lookup()`. One hot is better\n","      for TPUs.\n","\n","  Returns:\n","    float Tensor of shape [batch_size, seq_length, embedding_size].\n","  \"\"\"\n","  # This function assumes that the input is of shape [batch_size, seq_length,\n","  # num_inputs].\n","  #\n","  # If the input is a 2D tensor of shape [batch_size, seq_length], we\n","  # reshape to [batch_size, seq_length, 1].\n","  if input_ids.shape.ndims == 2:\n","    input_ids = tf.expand_dims(input_ids, axis=[-1])\n","\n","  embedding_table = tf.get_variable(\n","      name=word_embedding_name,\n","      shape=[vocab_size, embedding_size],\n","      initializer=create_initializer(initializer_range))\n","\n","  if use_one_hot_embeddings:\n","    flat_input_ids = tf.reshape(input_ids, [-1])\n","    one_hot_input_ids = tf.one_hot(flat_input_ids, depth=vocab_size)\n","    output = tf.matmul(one_hot_input_ids, embedding_table)\n","  else:\n","    output = tf.nn.embedding_lookup(embedding_table, input_ids)\n","\n","  input_shape = get_shape_list(input_ids)\n","\n","  output = tf.reshape(output,\n","                      input_shape[0:-1] + [input_shape[-1] * embedding_size])\n","  return (output, embedding_table)\n","\n","\n","def embedding_postprocessor(input_tensor,\n","                            use_token_type=False,\n","                            token_type_ids=None,\n","                            token_type_vocab_size=16,\n","                            token_type_embedding_name=\"token_type_embeddings\",\n","                            use_position_embeddings=True,\n","                            position_embedding_name=\"position_embeddings\",\n","                            initializer_range=0.02,\n","                            max_position_embeddings=512,\n","                            dropout_prob=0.1):\n","  \"\"\"Performs various post-processing on a word embedding tensor.\n","\n","  Args:\n","    input_tensor: float Tensor of shape [batch_size, seq_length,\n","      embedding_size].\n","    use_token_type: bool. Whether to add embeddings for `token_type_ids`.\n","    token_type_ids: (optional) int32 Tensor of shape [batch_size, seq_length].\n","      Must be specified if `use_token_type` is True.\n","    token_type_vocab_size: int. The vocabulary size of `token_type_ids`.\n","    token_type_embedding_name: string. The name of the embedding table variable\n","      for token type ids.\n","    use_position_embeddings: bool. Whether to add position embeddings for the\n","      position of each token in the sequence.\n","    position_embedding_name: string. The name of the embedding table variable\n","      for positional embeddings.\n","    initializer_range: float. Range of the weight initialization.\n","    max_position_embeddings: int. Maximum sequence length that might ever be\n","      used with this model. This can be longer than the sequence length of\n","      input_tensor, but cannot be shorter.\n","    dropout_prob: float. Dropout probability applied to the final output tensor.\n","\n","  Returns:\n","    float tensor with same shape as `input_tensor`.\n","\n","  Raises:\n","    ValueError: One of the tensor shapes or input values is invalid.\n","  \"\"\"\n","  input_shape = get_shape_list(input_tensor, expected_rank=3)\n","  batch_size = input_shape[0]\n","  seq_length = input_shape[1]\n","  width = input_shape[2]\n","\n","  output = input_tensor\n","\n","  if use_token_type:\n","    if token_type_ids is None:\n","      raise ValueError(\"`token_type_ids` must be specified if\"\n","                       \"`use_token_type` is True.\")\n","    token_type_table = tf.get_variable(\n","        name=token_type_embedding_name,\n","        shape=[token_type_vocab_size, width],\n","        initializer=create_initializer(initializer_range))\n","    # This vocab will be small so we always do one-hot here, since it is always\n","    # faster for a small vocabulary.\n","    flat_token_type_ids = tf.reshape(token_type_ids, [-1])\n","    one_hot_ids = tf.one_hot(flat_token_type_ids, depth=token_type_vocab_size)\n","    token_type_embeddings = tf.matmul(one_hot_ids, token_type_table)\n","    token_type_embeddings = tf.reshape(token_type_embeddings,\n","                                       [batch_size, seq_length, width])\n","    output += token_type_embeddings\n","\n","  if use_position_embeddings:\n","    assert_op = tf.assert_less_equal(seq_length, max_position_embeddings)\n","    with tf.control_dependencies([assert_op]):\n","      full_position_embeddings = tf.get_variable(\n","          name=position_embedding_name,\n","          shape=[max_position_embeddings, width],\n","          initializer=create_initializer(initializer_range))\n","      # Since the position embedding table is a learned variable, we create it\n","      # using a (long) sequence length `max_position_embeddings`. The actual\n","      # sequence length might be shorter than this, for faster training of\n","      # tasks that do not have long sequences.\n","      #\n","      # So `full_position_embeddings` is effectively an embedding table\n","      # for position [0, 1, 2, ..., max_position_embeddings-1], and the current\n","      # sequence has positions [0, 1, 2, ... seq_length-1], so we can just\n","      # perform a slice.\n","      position_embeddings = tf.slice(full_position_embeddings, [0, 0],\n","                                     [seq_length, -1])\n","      num_dims = len(output.shape.as_list())\n","\n","      # Only the last two dimensions are relevant (`seq_length` and `width`), so\n","      # we broadcast among the first dimensions, which is typically just\n","      # the batch size.\n","      position_broadcast_shape = []\n","      for _ in range(num_dims - 2):\n","        position_broadcast_shape.append(1)\n","      position_broadcast_shape.extend([seq_length, width])\n","      position_embeddings = tf.reshape(position_embeddings,\n","                                       position_broadcast_shape)\n","      output += position_embeddings\n","\n","  output = layer_norm_and_dropout(output, dropout_prob)\n","  return output\n","\n","\n","def create_attention_mask_from_input_mask(from_tensor, to_mask):\n","  \"\"\"Create 3D attention mask from a 2D tensor mask.\n","\n","  Args:\n","    from_tensor: 2D or 3D Tensor of shape [batch_size, from_seq_length, ...].\n","    to_mask: int32 Tensor of shape [batch_size, to_seq_length].\n","\n","  Returns:\n","    float Tensor of shape [batch_size, from_seq_length, to_seq_length].\n","  \"\"\"\n","  from_shape = get_shape_list(from_tensor, expected_rank=[2, 3])\n","  batch_size = from_shape[0]\n","  from_seq_length = from_shape[1]\n","\n","  to_shape = get_shape_list(to_mask, expected_rank=2)\n","  to_seq_length = to_shape[1]\n","\n","  to_mask = tf.cast(\n","      tf.reshape(to_mask, [batch_size, 1, to_seq_length]), tf.float32)\n","\n","  # We don't assume that `from_tensor` is a mask (although it could be). We\n","  # don't actually care if we attend *from* padding tokens (only *to* padding)\n","  # tokens so we create a tensor of all ones.\n","  #\n","  # `broadcast_ones` = [batch_size, from_seq_length, 1]\n","  broadcast_ones = tf.ones(\n","      shape=[batch_size, from_seq_length, 1], dtype=tf.float32)\n","\n","  # Here we broadcast along two dimensions to create the mask.\n","  mask = broadcast_ones * to_mask\n","\n","  return mask\n","\n","\n","def attention_layer(from_tensor,\n","                    to_tensor,\n","                    attention_mask=None,\n","                    num_attention_heads=1,\n","                    size_per_head=512,\n","                    query_act=None,\n","                    key_act=None,\n","                    value_act=None,\n","                    attention_probs_dropout_prob=0.0,\n","                    initializer_range=0.02,\n","                    do_return_2d_tensor=False,\n","                    batch_size=None,\n","                    from_seq_length=None,\n","                    to_seq_length=None):\n","  \"\"\"Performs multi-headed attention from `from_tensor` to `to_tensor`.\n","\n","  This is an implementation of multi-headed attention based on \"Attention\n","  is all you Need\". If `from_tensor` and `to_tensor` are the same, then\n","  this is self-attention. Each timestep in `from_tensor` attends to the\n","  corresponding sequence in `to_tensor`, and returns a fixed-with vector.\n","\n","  This function first projects `from_tensor` into a \"query\" tensor and\n","  `to_tensor` into \"key\" and \"value\" tensors. These are (effectively) a list\n","  of tensors of length `num_attention_heads`, where each tensor is of shape\n","  [batch_size, seq_length, size_per_head].\n","\n","  Then, the query and key tensors are dot-producted and scaled. These are\n","  softmaxed to obtain attention probabilities. The value tensors are then\n","  interpolated by these probabilities, then concatenated back to a single\n","  tensor and returned.\n","\n","  In practice, the multi-headed attention are done with transposes and\n","  reshapes rather than actual separate tensors.\n","\n","  Args:\n","    from_tensor: float Tensor of shape [batch_size, from_seq_length,\n","      from_width].\n","    to_tensor: float Tensor of shape [batch_size, to_seq_length, to_width].\n","    attention_mask: (optional) int32 Tensor of shape [batch_size,\n","      from_seq_length, to_seq_length]. The values should be 1 or 0. The\n","      attention scores will effectively be set to -infinity for any positions in\n","      the mask that are 0, and will be unchanged for positions that are 1.\n","    num_attention_heads: int. Number of attention heads.\n","    size_per_head: int. Size of each attention head.\n","    query_act: (optional) Activation function for the query transform.\n","    key_act: (optional) Activation function for the key transform.\n","    value_act: (optional) Activation function for the value transform.\n","    attention_probs_dropout_prob: (optional) float. Dropout probability of the\n","      attention probabilities.\n","    initializer_range: float. Range of the weight initializer.\n","    do_return_2d_tensor: bool. If True, the output will be of shape [batch_size\n","      * from_seq_length, num_attention_heads * size_per_head]. If False, the\n","      output will be of shape [batch_size, from_seq_length, num_attention_heads\n","      * size_per_head].\n","    batch_size: (Optional) int. If the input is 2D, this might be the batch size\n","      of the 3D version of the `from_tensor` and `to_tensor`.\n","    from_seq_length: (Optional) If the input is 2D, this might be the seq length\n","      of the 3D version of the `from_tensor`.\n","    to_seq_length: (Optional) If the input is 2D, this might be the seq length\n","      of the 3D version of the `to_tensor`.\n","\n","  Returns:\n","    float Tensor of shape [batch_size, from_seq_length,\n","      num_attention_heads * size_per_head]. (If `do_return_2d_tensor` is\n","      true, this will be of shape [batch_size * from_seq_length,\n","      num_attention_heads * size_per_head]).\n","\n","  Raises:\n","    ValueError: Any of the arguments or tensor shapes are invalid.\n","  \"\"\"\n","\n","  def transpose_for_scores(input_tensor, batch_size, num_attention_heads,\n","                           seq_length, width):\n","    output_tensor = tf.reshape(\n","        input_tensor, [batch_size, seq_length, num_attention_heads, width])\n","\n","    output_tensor = tf.transpose(output_tensor, [0, 2, 1, 3])\n","    return output_tensor\n","\n","  from_shape = get_shape_list(from_tensor, expected_rank=[2, 3])\n","  to_shape = get_shape_list(to_tensor, expected_rank=[2, 3])\n","\n","  if len(from_shape) != len(to_shape):\n","    raise ValueError(\n","        \"The rank of `from_tensor` must match the rank of `to_tensor`.\")\n","\n","  if len(from_shape) == 3:\n","    batch_size = from_shape[0]\n","    from_seq_length = from_shape[1]\n","    to_seq_length = to_shape[1]\n","  elif len(from_shape) == 2:\n","    if (batch_size is None or from_seq_length is None or to_seq_length is None):\n","      raise ValueError(\n","          \"When passing in rank 2 tensors to attention_layer, the values \"\n","          \"for `batch_size`, `from_seq_length`, and `to_seq_length` \"\n","          \"must all be specified.\")\n","\n","  # Scalar dimensions referenced here:\n","  #   B = batch size (number of sequences)\n","  #   F = `from_tensor` sequence length\n","  #   T = `to_tensor` sequence length\n","  #   N = `num_attention_heads`\n","  #   H = `size_per_head`\n","\n","  from_tensor_2d = reshape_to_matrix(from_tensor)\n","  to_tensor_2d = reshape_to_matrix(to_tensor)\n","\n","  # `query_layer` = [B*F, N*H]\n","  query_layer = tf.layers.dense(\n","      from_tensor_2d,\n","      num_attention_heads * size_per_head,\n","      activation=query_act,\n","      name=\"query\",\n","      kernel_initializer=create_initializer(initializer_range))\n","\n","  # `key_layer` = [B*T, N*H]\n","  key_layer = tf.layers.dense(\n","      to_tensor_2d,\n","      num_attention_heads * size_per_head,\n","      activation=key_act,\n","      name=\"key\",\n","      kernel_initializer=create_initializer(initializer_range))\n","\n","  # `value_layer` = [B*T, N*H]\n","  value_layer = tf.layers.dense(\n","      to_tensor_2d,\n","      num_attention_heads * size_per_head,\n","      activation=value_act,\n","      name=\"value\",\n","      kernel_initializer=create_initializer(initializer_range))\n","\n","  # `query_layer` = [B, N, F, H]\n","  query_layer = transpose_for_scores(query_layer, batch_size,\n","                                     num_attention_heads, from_seq_length,\n","                                     size_per_head)\n","\n","  # `key_layer` = [B, N, T, H]\n","  key_layer = transpose_for_scores(key_layer, batch_size, num_attention_heads,\n","                                   to_seq_length, size_per_head)\n","\n","  # Take the dot product between \"query\" and \"key\" to get the raw\n","  # attention scores.\n","  # `attention_scores` = [B, N, F, T]\n","  attention_scores = tf.matmul(query_layer, key_layer, transpose_b=True)\n","  attention_scores = tf.multiply(attention_scores,\n","                                 1.0 / math.sqrt(float(size_per_head)))\n","\n","  if attention_mask is not None:\n","    # `attention_mask` = [B, 1, F, T]\n","    attention_mask = tf.expand_dims(attention_mask, axis=[1])\n","\n","    # Since attention_mask is 1.0 for positions we want to attend and 0.0 for\n","    # masked positions, this operation will create a tensor which is 0.0 for\n","    # positions we want to attend and -10000.0 for masked positions.\n","    adder = (1.0 - tf.cast(attention_mask, tf.float32)) * -10000.0\n","\n","    # Since we are adding it to the raw scores before the softmax, this is\n","    # effectively the same as removing these entirely.\n","    attention_scores += adder\n","\n","  # Normalize the attention scores to probabilities.\n","  # `attention_probs` = [B, N, F, T]\n","  attention_probs = tf.nn.softmax(attention_scores)\n","\n","  # This is actually dropping out entire tokens to attend to, which might\n","  # seem a bit unusual, but is taken from the original Transformer paper.\n","  attention_probs = dropout(attention_probs, attention_probs_dropout_prob)\n","\n","  # `value_layer` = [B, T, N, H]\n","  value_layer = tf.reshape(\n","      value_layer,\n","      [batch_size, to_seq_length, num_attention_heads, size_per_head])\n","\n","  # `value_layer` = [B, N, T, H]\n","  value_layer = tf.transpose(value_layer, [0, 2, 1, 3])\n","\n","  # `context_layer` = [B, N, F, H]\n","  context_layer = tf.matmul(attention_probs, value_layer)\n","\n","  # `context_layer` = [B, F, N, H]\n","  context_layer = tf.transpose(context_layer, [0, 2, 1, 3])\n","\n","  if do_return_2d_tensor:\n","    # `context_layer` = [B*F, N*H]\n","    context_layer = tf.reshape(\n","        context_layer,\n","        [batch_size * from_seq_length, num_attention_heads * size_per_head])\n","  else:\n","    # `context_layer` = [B, F, N*H]\n","    context_layer = tf.reshape(\n","        context_layer,\n","        [batch_size, from_seq_length, num_attention_heads * size_per_head])\n","\n","  return context_layer\n","\n","\n","def transformer_model(input_tensor,\n","                      attention_mask=None,\n","                      hidden_size=768,\n","                      num_hidden_layers=12,\n","                      num_attention_heads=12,\n","                      intermediate_size=3072,\n","                      intermediate_act_fn=gelu,\n","                      hidden_dropout_prob=0.1,\n","                      attention_probs_dropout_prob=0.1,\n","                      initializer_range=0.02,\n","                      do_return_all_layers=False):\n","  \"\"\"Multi-headed, multi-layer Transformer from \"Attention is All You Need\".\n","\n","  This is almost an exact implementation of the original Transformer encoder.\n","\n","  See the original paper:\n","  https://arxiv.org/abs/1706.03762\n","\n","  Also see:\n","  https://github.com/tensorflow/tensor2tensor/blob/master/tensor2tensor/models/transformer.py\n","\n","  Args:\n","    input_tensor: float Tensor of shape [batch_size, seq_length, hidden_size].\n","    attention_mask: (optional) int32 Tensor of shape [batch_size, seq_length,\n","      seq_length], with 1 for positions that can be attended to and 0 in\n","      positions that should not be.\n","    hidden_size: int. Hidden size of the Transformer.\n","    num_hidden_layers: int. Number of layers (blocks) in the Transformer.\n","    num_attention_heads: int. Number of attention heads in the Transformer.\n","    intermediate_size: int. The size of the \"intermediate\" (a.k.a., feed\n","      forward) layer.\n","    intermediate_act_fn: function. The non-linear activation function to apply\n","      to the output of the intermediate/feed-forward layer.\n","    hidden_dropout_prob: float. Dropout probability for the hidden layers.\n","    attention_probs_dropout_prob: float. Dropout probability of the attention\n","      probabilities.\n","    initializer_range: float. Range of the initializer (stddev of truncated\n","      normal).\n","    do_return_all_layers: Whether to also return all layers or just the final\n","      layer.\n","\n","  Returns:\n","    float Tensor of shape [batch_size, seq_length, hidden_size], the final\n","    hidden layer of the Transformer.\n","\n","  Raises:\n","    ValueError: A Tensor shape or parameter is invalid.\n","  \"\"\"\n","  if hidden_size % num_attention_heads != 0:\n","    raise ValueError(\n","        \"The hidden size (%d) is not a multiple of the number of attention \"\n","        \"heads (%d)\" % (hidden_size, num_attention_heads))\n","\n","  attention_head_size = int(hidden_size / num_attention_heads)\n","  input_shape = get_shape_list(input_tensor, expected_rank=3)\n","  batch_size = input_shape[0]\n","  seq_length = input_shape[1]\n","  input_width = input_shape[2]\n","\n","  # The Transformer performs sum residuals on all layers so the input needs\n","  # to be the same as the hidden size.\n","  if input_width != hidden_size:\n","    raise ValueError(\"The width of the input tensor (%d) != hidden size (%d)\" %\n","                     (input_width, hidden_size))\n","\n","  # We keep the representation as a 2D tensor to avoid re-shaping it back and\n","  # forth from a 3D tensor to a 2D tensor. Re-shapes are normally free on\n","  # the GPU/CPU but may not be free on the TPU, so we want to minimize them to\n","  # help the optimizer.\n","  prev_output = reshape_to_matrix(input_tensor)\n","\n","  all_layer_outputs = []\n","  for layer_idx in range(num_hidden_layers):\n","    with tf.variable_scope(\"layer_%d\" % layer_idx):\n","      layer_input = prev_output\n","\n","      with tf.variable_scope(\"attention\"):\n","        attention_heads = []\n","        with tf.variable_scope(\"self\"):\n","          attention_head = attention_layer(\n","              from_tensor=layer_input,\n","              to_tensor=layer_input,\n","              attention_mask=attention_mask,\n","              num_attention_heads=num_attention_heads,\n","              size_per_head=attention_head_size,\n","              attention_probs_dropout_prob=attention_probs_dropout_prob,\n","              initializer_range=initializer_range,\n","              do_return_2d_tensor=True,\n","              batch_size=batch_size,\n","              from_seq_length=seq_length,\n","              to_seq_length=seq_length)\n","          attention_heads.append(attention_head)\n","\n","        attention_output = None\n","        if len(attention_heads) == 1:\n","          attention_output = attention_heads[0]\n","        else:\n","          # In the case where we have other sequences, we just concatenate\n","          # them to the self-attention head before the projection.\n","          attention_output = tf.concat(attention_heads, axis=-1)\n","\n","        # Run a linear projection of `hidden_size` then add a residual\n","        # with `layer_input`.\n","        with tf.variable_scope(\"output\"):\n","          attention_output = tf.layers.dense(\n","              attention_output,\n","              hidden_size,\n","              kernel_initializer=create_initializer(initializer_range))\n","          attention_output = dropout(attention_output, hidden_dropout_prob)\n","          attention_output = layer_norm(attention_output + layer_input)\n","\n","      # The activation is only applied to the \"intermediate\" hidden layer.\n","      with tf.variable_scope(\"intermediate\"):\n","        intermediate_output = tf.layers.dense(\n","            attention_output,\n","            intermediate_size,\n","            activation=intermediate_act_fn,\n","            kernel_initializer=create_initializer(initializer_range))\n","\n","      # Down-project back to `hidden_size` then add the residual.\n","      with tf.variable_scope(\"output\"):\n","        layer_output = tf.layers.dense(\n","            intermediate_output,\n","            hidden_size,\n","            kernel_initializer=create_initializer(initializer_range))\n","        layer_output = dropout(layer_output, hidden_dropout_prob)\n","        layer_output = layer_norm(layer_output + attention_output)\n","        prev_output = layer_output\n","        all_layer_outputs.append(layer_output)\n","\n","  if do_return_all_layers:\n","    final_outputs = []\n","    for layer_output in all_layer_outputs:\n","      final_output = reshape_from_matrix(layer_output, input_shape)\n","      final_outputs.append(final_output)\n","    return final_outputs\n","  else:\n","    final_output = reshape_from_matrix(prev_output, input_shape)\n","    return final_output\n","\n","\n","def get_shape_list(tensor, expected_rank=None, name=None):\n","  \"\"\"Returns a list of the shape of tensor, preferring static dimensions.\n","\n","  Args:\n","    tensor: A tf.Tensor object to find the shape of.\n","    expected_rank: (optional) int. The expected rank of `tensor`. If this is\n","      specified and the `tensor` has a different rank, and exception will be\n","      thrown.\n","    name: Optional name of the tensor for the error message.\n","\n","  Returns:\n","    A list of dimensions of the shape of tensor. All static dimensions will\n","    be returned as python integers, and dynamic dimensions will be returned\n","    as tf.Tensor scalars.\n","  \"\"\"\n","  if name is None:\n","    name = tensor.name\n","\n","  if expected_rank is not None:\n","    assert_rank(tensor, expected_rank, name)\n","\n","  shape = tensor.shape.as_list()\n","\n","  non_static_indexes = []\n","  for (index, dim) in enumerate(shape):\n","    if dim is None:\n","      non_static_indexes.append(index)\n","\n","  if not non_static_indexes:\n","    return shape\n","\n","  dyn_shape = tf.shape(tensor)\n","  for index in non_static_indexes:\n","    shape[index] = dyn_shape[index]\n","  return shape\n","\n","\n","def reshape_to_matrix(input_tensor):\n","  \"\"\"Reshapes a >= rank 2 tensor to a rank 2 tensor (i.e., a matrix).\"\"\"\n","  ndims = input_tensor.shape.ndims\n","  if ndims < 2:\n","    raise ValueError(\"Input tensor must have at least rank 2. Shape = %s\" %\n","                     (input_tensor.shape))\n","  if ndims == 2:\n","    return input_tensor\n","\n","  width = input_tensor.shape[-1]\n","  output_tensor = tf.reshape(input_tensor, [-1, width])\n","  return output_tensor\n","\n","\n","def reshape_from_matrix(output_tensor, orig_shape_list):\n","  \"\"\"Reshapes a rank 2 tensor back to its original rank >= 2 tensor.\"\"\"\n","  if len(orig_shape_list) == 2:\n","    return output_tensor\n","\n","  output_shape = get_shape_list(output_tensor)\n","\n","  orig_dims = orig_shape_list[0:-1]\n","  width = output_shape[-1]\n","\n","  return tf.reshape(output_tensor, orig_dims + [width])\n","\n","\n","def assert_rank(tensor, expected_rank, name=None):\n","  \"\"\"Raises an exception if the tensor rank is not of the expected rank.\n","\n","  Args:\n","    tensor: A tf.Tensor to check the rank of.\n","    expected_rank: Python integer or list of integers, expected rank.\n","    name: Optional name of the tensor for the error message.\n","\n","  Raises:\n","    ValueError: If the expected shape doesn't match the actual shape.\n","  \"\"\"\n","  if name is None:\n","    name = tensor.name\n","\n","  expected_rank_dict = {}\n","  if isinstance(expected_rank, six.integer_types):\n","    expected_rank_dict[expected_rank] = True\n","  else:\n","    for x in expected_rank:\n","      expected_rank_dict[x] = True\n","\n","  actual_rank = tensor.shape.ndims\n","  if actual_rank not in expected_rank_dict:\n","    scope_name = tf.get_variable_scope().name\n","    raise ValueError(\n","        \"For the tensor `%s` in scope `%s`, the actual rank \"\n","        \"`%d` (shape = %s) is not equal to the expected rank `%s`\" %\n","        (name, scope_name, actual_rank, str(tensor.shape), str(expected_rank)))"],"metadata":{"id":"_VjI-AeieksC","executionInfo":{"status":"ok","timestamp":1701616922830,"user_tz":-540,"elapsed":12,"user":{"displayName":"이태후","userId":"03468433647806446322"}}},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":["### optimizer (copyright : BioBERT optimization.py)"],"metadata":{"id":"Aelz7c1jJJwI"}},{"cell_type":"code","source":["# coding=utf-8\n","# Copyright 2018 The Google AI Language Team Authors.\n","#\n","# Licensed under the Apache License, Version 2.0 (the \"License\");\n","# you may not use this file except in compliance with the License.\n","# You may obtain a copy of the License at\n","#\n","#     http://www.apache.org/licenses/LICENSE-2.0\n","#\n","# Unless required by applicable law or agreed to in writing, software\n","# distributed under the License is distributed on an \"AS IS\" BASIS,\n","# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","# See the License for the specific language governing permissions and\n","# limitations under the License.\n","\"\"\"Functions and classes related to optimization (weight updates).\"\"\"\n","\n","from __future__ import absolute_import\n","from __future__ import division\n","from __future__ import print_function\n","\n","import re\n","import tensorflow as tf\n","\n","\n","def create_optimizer(loss, init_lr, num_train_steps, num_warmup_steps, use_tpu):\n","  \"\"\"Creates an optimizer training op.\"\"\"\n","  global_step = tf.train.get_or_create_global_step()\n","\n","  learning_rate = tf.constant(value=init_lr, shape=[], dtype=tf.float32)\n","\n","  # Implements linear decay of the learning rate.\n","  learning_rate = tf.train.polynomial_decay(\n","      learning_rate,\n","      global_step,\n","      num_train_steps,\n","      end_learning_rate=0.0,\n","      power=1.0,\n","      cycle=False)\n","\n","  # Implements linear warmup. I.e., if global_step < num_warmup_steps, the\n","  # learning rate will be `global_step/num_warmup_steps * init_lr`.\n","  if num_warmup_steps:\n","    global_steps_int = tf.cast(global_step, tf.int32)\n","    warmup_steps_int = tf.constant(num_warmup_steps, dtype=tf.int32)\n","\n","    global_steps_float = tf.cast(global_steps_int, tf.float32)\n","    warmup_steps_float = tf.cast(warmup_steps_int, tf.float32)\n","\n","    warmup_percent_done = global_steps_float / warmup_steps_float\n","    warmup_learning_rate = init_lr * warmup_percent_done\n","\n","    is_warmup = tf.cast(global_steps_int < warmup_steps_int, tf.float32)\n","    learning_rate = (\n","        (1.0 - is_warmup) * learning_rate + is_warmup * warmup_learning_rate)\n","\n","  # It is recommended that you use this optimizer for fine tuning, since this\n","  # is how the model was trained (note that the Adam m/v variables are NOT\n","  # loaded from init_checkpoint.)\n","  optimizer = AdamWeightDecayOptimizer(\n","      learning_rate=learning_rate,\n","      weight_decay_rate=0.01,\n","      beta_1=0.9,\n","      beta_2=0.999,\n","      epsilon=1e-6,\n","      exclude_from_weight_decay=[\"LayerNorm\", \"layer_norm\", \"bias\"])\n","\n","  if use_tpu:\n","    optimizer = tf.contrib.tpu.CrossShardOptimizer(optimizer)\n","\n","  tvars = tf.trainable_variables()\n","  grads = tf.gradients(loss, tvars)\n","\n","  # This is how the model was pre-trained.\n","  (grads, _) = tf.clip_by_global_norm(grads, clip_norm=1.0)\n","\n","  train_op = optimizer.apply_gradients(\n","      zip(grads, tvars), global_step=global_step)\n","\n","  # Normally the global step update is done inside of `apply_gradients`.\n","  # However, `AdamWeightDecayOptimizer` doesn't do this. But if you use\n","  # a different optimizer, you should probably take this line out.\n","  new_global_step = global_step + 1\n","  train_op = tf.group(train_op, [global_step.assign(new_global_step)])\n","  return train_op\n","\n","\n","class AdamWeightDecayOptimizer(tf.compat.v1.train.Optimizer):\n","  \"\"\"A basic Adam optimizer that includes \"correct\" L2 weight decay.\"\"\"\n","\n","  def __init__(self,\n","               learning_rate,\n","               weight_decay_rate=0.0,\n","               beta_1=0.9,\n","               beta_2=0.999,\n","               epsilon=1e-6,\n","               exclude_from_weight_decay=None,\n","               name=\"AdamWeightDecayOptimizer\"):\n","    \"\"\"Constructs a AdamWeightDecayOptimizer.\"\"\"\n","    super(AdamWeightDecayOptimizer, self).__init__(False, name)\n","\n","    self.learning_rate = learning_rate\n","    self.weight_decay_rate = weight_decay_rate\n","    self.beta_1 = beta_1\n","    self.beta_2 = beta_2\n","    self.epsilon = epsilon\n","    self.exclude_from_weight_decay = exclude_from_weight_decay\n","\n","  def apply_gradients(self, grads_and_vars, global_step=None, name=None):\n","    \"\"\"See base class.\"\"\"\n","    assignments = []\n","    for (grad, param) in grads_and_vars:\n","      if grad is None or param is None:\n","        continue\n","\n","      param_name = self._get_variable_name(param.name)\n","\n","      m = tf.get_variable(\n","          name=param_name + \"/adam_m\",\n","          shape=param.shape.as_list(),\n","          dtype=tf.float32,\n","          trainable=False,\n","          initializer=tf.zeros_initializer())\n","      v = tf.get_variable(\n","          name=param_name + \"/adam_v\",\n","          shape=param.shape.as_list(),\n","          dtype=tf.float32,\n","          trainable=False,\n","          initializer=tf.zeros_initializer())\n","\n","      # Standard Adam update.\n","      next_m = (\n","          tf.multiply(self.beta_1, m) + tf.multiply(1.0 - self.beta_1, grad))\n","      next_v = (\n","          tf.multiply(self.beta_2, v) + tf.multiply(1.0 - self.beta_2,\n","                                                    tf.square(grad)))\n","\n","      update = next_m / (tf.sqrt(next_v) + self.epsilon)\n","\n","      # Just adding the square of the weights to the loss function is *not*\n","      # the correct way of using L2 regularization/weight decay with Adam,\n","      # since that will interact with the m and v parameters in strange ways.\n","      #\n","      # Instead we want ot decay the weights in a manner that doesn't interact\n","      # with the m/v parameters. This is equivalent to adding the square\n","      # of the weights to the loss with plain (non-momentum) SGD.\n","      if self._do_use_weight_decay(param_name):\n","        update += self.weight_decay_rate * param\n","\n","      update_with_lr = self.learning_rate * update\n","\n","      next_param = param - update_with_lr\n","\n","      assignments.extend(\n","          [param.assign(next_param),\n","           m.assign(next_m),\n","           v.assign(next_v)])\n","    return tf.group(*assignments, name=name)\n","\n","  def _do_use_weight_decay(self, param_name):\n","    \"\"\"Whether to use L2 weight decay for `param_name`.\"\"\"\n","    if not self.weight_decay_rate:\n","      return False\n","    if self.exclude_from_weight_decay:\n","      for r in self.exclude_from_weight_decay:\n","        if re.search(r, param_name) is not None:\n","          return False\n","    return True\n","\n","  def _get_variable_name(self, param_name):\n","    \"\"\"Get the variable name from the tensor name.\"\"\"\n","    m = re.match(\"^(.*):\\\\d+$\", param_name)\n","    if m is not None:\n","      param_name = m.group(1)\n","    return param_name"],"metadata":{"id":"cIVeubguJN38","executionInfo":{"status":"ok","timestamp":1701616922830,"user_tz":-540,"elapsed":12,"user":{"displayName":"이태후","userId":"03468433647806446322"}}},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":["### modeling"],"metadata":{"id":"x0BqK9IEHPjL"}},{"cell_type":"code","source":["def create_model(bert_config, is_training, input_ids, input_mask, segment_ids, use_one_hot_embeddings):\n","\n","  '''create classification model'''\n","\n","  model = BertModel(\n","      config=bert_config,\n","            is_training=is_training,\n","      input_ids=input_ids,\n","      input_mask=input_mask,\n","      token_type_ids=segment_ids,\n","      use_one_hot_embeddings=use_one_hot_embeddings\n","  )\n","\n","  final_hidden = model.get_sequence_output()\n","\n","  final_hidden_shape = get_shape_list(final_hidden, expected_rank=3)\n","  batch_size = final_hidden_shape[0]\n","  seq_length = final_hidden_shape[1]\n","  hidden_size = final_hidden_shape[2]\n","\n","  output_weights = tf.get_variable(\n","      \"cls/squad/output_weights\", [2, hidden_size],\n","      initializer=tf.truncated_normal_initializer(stddev=0.02))\n","\n","  output_bias = tf.get_variable(\n","      \"cls/squad/output_bias\", [2], initializer=tf.zeros_initializer())\n","\n","  final_hidden_matrix = tf.reshape(final_hidden,\n","                                   [batch_size * seq_length, hidden_size])\n","  logits = tf.matmul(final_hidden_matrix, output_weights, transpose_b=True)\n","  logits = tf.nn.bias_add(logits, output_bias)\n","\n","  logits = tf.reshape(logits, [batch_size, seq_length, 2])\n","  logits = tf.transpose(logits, [2, 0, 1])\n","\n","  unstacked_logits = tf.unstack(logits, axis=0)\n","\n","  (start_logits, end_logits) = (unstacked_logits[0], unstacked_logits[1])\n","\n","  return (start_logits, end_logits)"],"metadata":{"id":"ppuXkWVxWPnJ","executionInfo":{"status":"ok","timestamp":1701616922830,"user_tz":-540,"elapsed":11,"user":{"displayName":"이태후","userId":"03468433647806446322"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["def model_fn_builder(bert_config, init_checkpoint, learning_rate,\n","                     num_train_steps, num_warmup_steps, use_one_hot_embeddings):\n","\n","  def model_fn(features, labels, mode, params):\n","\n","    tf.logging.info(\"*** Features ***\")\n","    for name in sorted(features.keys()):\n","      tf.logging.info(\"  name = %s, shape = %s\" % (name, features[name].shape))\n","\n","    unique_ids = features[\"unique_ids\"]\n","    input_ids = features[\"input_ids\"]\n","    input_mask = features[\"input_mask\"]\n","    segment_ids = features[\"segment_ids\"]\n","\n","    is_training = (mode == tf.estimator.ModeKeys.TRAIN)\n","\n","    (start_logits, end_logits) = create_model(\n","        bert_config=bert_config,\n","        is_training=is_training,\n","        input_ids=input_ids,\n","        input_mask=input_mask,\n","        segment_ids=segment_ids,\n","        use_one_hot_embeddings=use_one_hot_embeddings)\n","\n","    tvars = tf.trainable_variables()\n","\n","    initialized_variable_names = {}\n","    scaffold_fn = None\n","    if init_checkpoint:\n","      (assignment_map, initialized_variable_names) = get_assignment_map_from_checkpoint(tvars, init_checkpoint)\n","      tf.train.init_from_checkpoint(init_checkpoint, assignment_map)\n","\n","    tf.logging.info(\"**** Trainable Variables ****\")\n","    for var in tvars:\n","      init_string = \"\"\n","      if var.name in initialized_variable_names:\n","        init_string = \", *INIT_FROM_CKPT*\"\n","      tf.logging.info(\"  name = %s, shape = %s%s\", var.name, var.shape,\n","                      init_string)\n","\n","    output_spec = None\n","    if mode == tf.estimator.ModeKeys.TRAIN:\n","      seq_length = get_shape_list(input_ids)[1]\n","\n","      def compute_loss(logits, positions):\n","        one_hot_positions = tf.one_hot(\n","            positions, depth=seq_length, dtype=tf.float32)\n","        log_probs = tf.nn.log_softmax(logits, axis=-1)\n","        loss = -tf.reduce_mean(\n","            tf.reduce_sum(one_hot_positions * log_probs, axis=-1))\n","        return loss\n","\n","      start_positions = features[\"start_positions\"]\n","      end_positions = features[\"end_positions\"]\n","\n","      start_loss = compute_loss(start_logits, start_positions)\n","      end_loss = compute_loss(end_logits, end_positions)\n","\n","      total_loss = (start_loss + end_loss) / 2.0\n","\n","      train_op = create_optimizer(\n","          total_loss, learning_rate, num_train_steps, num_warmup_steps)\n","\n","      output_spec = tf.contrib.tpu.TPUEstimatorSpec(\n","          mode=mode,\n","          loss=total_loss,\n","          train_op=train_op,\n","          scaffold_fn=scaffold_fn)\n","    elif mode == tf.estimator.ModeKeys.PREDICT:\n","      predictions = {\n","          \"unique_ids\": unique_ids,\n","          \"start_logits\": start_logits,\n","          \"end_logits\": end_logits,\n","      }\n","      output_spec = tf.contrib.tpu.TPUEstimatorSpec(\n","          mode=mode, predictions=predictions, scaffold_fn=scaffold_fn)\n","    else:\n","      raise ValueError(\n","          \"Only TRAIN and PREDICT modes are supported: %s\" % (mode))\n","\n","    return output_spec\n","\n","  return model_fn"],"metadata":{"id":"UXWV2SrkHwSK","executionInfo":{"status":"ok","timestamp":1701616922830,"user_tz":-540,"elapsed":11,"user":{"displayName":"이태후","userId":"03468433647806446322"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["def input_fn_builder(input_file, seq_length, is_training, drop_remainder):\n","  \"\"\"Creates an `input_fn` closure to be passed to TPUEstimator.\"\"\"\n","\n","  name_to_features = {\n","      \"unique_ids\": tf.FixedLenFeature([], tf.int64),\n","      \"input_ids\": tf.FixedLenFeature([seq_length], tf.int64),\n","      \"input_mask\": tf.FixedLenFeature([seq_length], tf.int64),\n","      \"segment_ids\": tf.FixedLenFeature([seq_length], tf.int64),\n","  }\n","\n","  if is_training:\n","    name_to_features[\"start_positions\"] = tf.FixedLenFeature([], tf.int64)\n","    name_to_features[\"end_positions\"] = tf.FixedLenFeature([], tf.int64)\n","\n","  def _decode_record(record, name_to_features):\n","    \"\"\"Decodes a record to a TensorFlow example.\"\"\"\n","    example = tf.parse_single_example(record, name_to_features)\n","\n","    # tf.Example only supports tf.int64, but the TPU only supports tf.int32.\n","    # So cast all int64 to int32.\n","    for name in list(example.keys()):\n","      t = example[name]\n","      if t.dtype == tf.int64:\n","        t = tf.to_int32(t)\n","      example[name] = t\n","\n","    return example\n","\n","  def input_fn(params):\n","    \"\"\"The actual input function.\"\"\"\n","    batch_size = params[\"batch_size\"]\n","\n","    # For training, we want a lot of parallel reading and shuffling.\n","    # For eval, we want no shuffling and parallel reading doesn't matter.\n","    d = tf.data.TFRecordDataset(input_file)\n","    if is_training:\n","      d = d.repeat()\n","      d = d.shuffle(buffer_size=100)\n","\n","    d = d.apply(\n","        tf.contrib.data.map_and_batch(\n","            lambda record: _decode_record(record, name_to_features),\n","            batch_size=batch_size,\n","            drop_remainder=drop_remainder))\n","\n","    return d\n","\n","  return input_fn"],"metadata":{"id":"IfKhSOGHKNsN","executionInfo":{"status":"ok","timestamp":1701616922831,"user_tz":-540,"elapsed":12,"user":{"displayName":"이태후","userId":"03468433647806446322"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["RawResult = collections.namedtuple(\"RawResult\",\n","                                   [\"unique_id\", \"start_logits\", \"end_logits\"])"],"metadata":{"id":"2W90AioVKPV-","executionInfo":{"status":"ok","timestamp":1701616922831,"user_tz":-540,"elapsed":12,"user":{"displayName":"이태후","userId":"03468433647806446322"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["def _get_best_indexes(logits, n_best_size):\n","  \"\"\"Get the n-best logits from a list.\"\"\"\n","  index_and_score = sorted(enumerate(logits), key=lambda x: x[1], reverse=True)\n","\n","  best_indexes = []\n","  for i in range(len(index_and_score)):\n","    if i >= n_best_size:\n","      break\n","    best_indexes.append(index_and_score[i][0])\n","  return best_indexes"],"metadata":{"id":"cglk30C0KgJy","executionInfo":{"status":"ok","timestamp":1701616922831,"user_tz":-540,"elapsed":11,"user":{"displayName":"이태후","userId":"03468433647806446322"}}},"execution_count":24,"outputs":[]},{"cell_type":"code","source":["def _compute_softmax(scores):\n","  \"\"\"Compute softmax probability over raw logits.\"\"\"\n","  if not scores:\n","    return []\n","\n","  max_score = None\n","  for score in scores:\n","    if max_score is None or score > max_score:\n","      max_score = score\n","\n","  exp_scores = []\n","  total_sum = 0.0\n","  for score in scores:\n","    x = math.exp(score - max_score)\n","    exp_scores.append(x)\n","    total_sum += x\n","\n","  probs = []\n","  for score in exp_scores:\n","    probs.append(score / total_sum)\n","  return probs"],"metadata":{"id":"G2Ya7tbsLN5l","executionInfo":{"status":"ok","timestamp":1701616922831,"user_tz":-540,"elapsed":11,"user":{"displayName":"이태후","userId":"03468433647806446322"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","source":["FLAGS = flags.FLAGS"],"metadata":{"id":"62AbPDyyLdXO","executionInfo":{"status":"ok","timestamp":1701616922831,"user_tz":-540,"elapsed":11,"user":{"displayName":"이태후","userId":"03468433647806446322"}}},"execution_count":26,"outputs":[]},{"cell_type":"code","source":["def get_final_text(pred_text, orig_text, do_lower_case):\n","\n","  \"\"\"Project the tokenized prediction back to the original text.\"\"\"\n","\n","  def _strip_spaces(text):\n","    ns_chars = []\n","    ns_to_s_map = collections.OrderedDict()\n","    for (i, c) in enumerate(text):\n","      if c == \" \":\n","        continue\n","      ns_to_s_map[len(ns_chars)] = i\n","      ns_chars.append(c)\n","    ns_text = \"\".join(ns_chars)\n","    return (ns_text, ns_to_s_map)\n","\n","  # We first tokenize `orig_text`, strip whitespace from the result\n","  # and `pred_text`, and check if they are the same length. If they are\n","  # NOT the same length, the heuristic has failed. If they are the same\n","  # length, we assume the characters are one-to-one aligned.\n","  tokenizer = BasicTokenizer(do_lower_case=do_lower_case)\n","\n","  tok_text = \" \".join(tokenizer.tokenize(orig_text))\n","\n","  start_position = tok_text.find(pred_text)\n","  if start_position == -1:\n","    if FLAGS.verbose_logging:\n","      tf.logging.info(\n","          \"Unable to find text: '%s' in '%s'\" % (pred_text, orig_text))\n","    return orig_text\n","  end_position = start_position + len(pred_text) - 1\n","\n","  (orig_ns_text, orig_ns_to_s_map) = _strip_spaces(orig_text)\n","  (tok_ns_text, tok_ns_to_s_map) = _strip_spaces(tok_text)\n","\n","  if len(orig_ns_text) != len(tok_ns_text):\n","    if FLAGS.verbose_logging:\n","      tf.logging.info(\"Length not equal after stripping spaces: '%s' vs '%s'\",\n","                      orig_ns_text, tok_ns_text)\n","    return orig_text\n","\n","  # We then project the characters in `pred_text` back to `orig_text` using\n","  # the character-to-character alignment.\n","  tok_s_to_ns_map = {}\n","  for (i, tok_index) in six.iteritems(tok_ns_to_s_map):\n","    tok_s_to_ns_map[tok_index] = i\n","\n","  orig_start_position = None\n","  if start_position in tok_s_to_ns_map:\n","    ns_start_position = tok_s_to_ns_map[start_position]\n","    if ns_start_position in orig_ns_to_s_map:\n","      orig_start_position = orig_ns_to_s_map[ns_start_position]\n","\n","  if orig_start_position is None:\n","    if FLAGS.verbose_logging:\n","      tf.logging.info(\"Couldn't map start position\")\n","    return orig_text\n","\n","  orig_end_position = None\n","  if end_position in tok_s_to_ns_map:\n","    ns_end_position = tok_s_to_ns_map[end_position]\n","    if ns_end_position in orig_ns_to_s_map:\n","      orig_end_position = orig_ns_to_s_map[ns_end_position]\n","\n","  if orig_end_position is None:\n","    if FLAGS.verbose_logging:\n","      tf.logging.info(\"Couldn't map end position\")\n","    return orig_text\n","\n","  output_text = orig_text[orig_start_position:(orig_end_position + 1)]\n","  return output_text"],"metadata":{"id":"NNKpBD10LXQ3","executionInfo":{"status":"ok","timestamp":1701616922831,"user_tz":-540,"elapsed":11,"user":{"displayName":"이태후","userId":"03468433647806446322"}}},"execution_count":27,"outputs":[]},{"cell_type":"code","source":["def write_predictions(all_examples, all_features, all_results, n_best_size,\n","                      max_answer_length, do_lower_case, output_prediction_file,\n","                      output_nbest_file, output_null_log_odds_file):\n","  \"\"\"Write final predictions to the json file and log-odds of null if needed.\"\"\"\n","  tf.logging.info(\"Writing predictions to: %s\" % (output_prediction_file))\n","  tf.logging.info(\"Writing nbest to: %s\" % (output_nbest_file))\n","\n","  example_index_to_features = collections.defaultdict(list)\n","  for feature in all_features:\n","    example_index_to_features[feature.example_index].append(feature)\n","\n","  unique_id_to_result = {}\n","  for result in all_results:\n","    unique_id_to_result[result.unique_id] = result\n","\n","  _PrelimPrediction = collections.namedtuple(  # pylint: disable=invalid-name\n","      \"PrelimPrediction\",\n","      [\"feature_index\", \"start_index\", \"end_index\", \"start_logit\", \"end_logit\"])\n","\n","  all_predictions = collections.OrderedDict()\n","  all_nbest_json = collections.OrderedDict()\n","  scores_diff_json = collections.OrderedDict()\n","\n","  for (example_index, example) in enumerate(all_examples):\n","    features = example_index_to_features[example_index]\n","\n","    prelim_predictions = []\n","    # keep track of the minimum score of null start+end of position 0\n","    score_null = 1000000  # large and positive\n","    min_null_feature_index = 0  # the paragraph slice with min mull score\n","    null_start_logit = 0  # the start logit at the slice with min null score\n","    null_end_logit = 0  # the end logit at the slice with min null score\n","    for (feature_index, feature) in enumerate(features):\n","      result = unique_id_to_result[feature.unique_id]\n","      start_indexes = _get_best_indexes(result.start_logits, n_best_size)\n","      end_indexes = _get_best_indexes(result.end_logits, n_best_size)\n","      # if we could have irrelevant answers, get the min score of irrelevant\n","\n","      for start_index in start_indexes:\n","        for end_index in end_indexes:\n","          # We could hypothetically create invalid predictions, e.g., predict\n","          # that the start of the span is in the question. We throw out all\n","          # invalid predictions.\n","          if start_index >= len(feature.tokens):\n","            continue\n","          if end_index >= len(feature.tokens):\n","            continue\n","          if start_index not in feature.token_to_orig_map:\n","            continue\n","          if end_index not in feature.token_to_orig_map:\n","            continue\n","          if not feature.token_is_max_context.get(start_index, False):\n","            continue\n","          if end_index < start_index:\n","            continue\n","          length = end_index - start_index + 1\n","          if length > max_answer_length:\n","            continue\n","          prelim_predictions.append(\n","              _PrelimPrediction(\n","                  feature_index=feature_index,\n","                  start_index=start_index,\n","                  end_index=end_index,\n","                  start_logit=result.start_logits[start_index],\n","                  end_logit=result.end_logits[end_index]))\n","\n","    prelim_predictions = sorted(\n","        prelim_predictions,\n","        key=lambda x: (x.start_logit + x.end_logit),\n","        reverse=True)\n","\n","    _NbestPrediction = collections.namedtuple(  # pylint: disable=invalid-name\n","        \"NbestPrediction\", [\"text\", \"start_logit\", \"end_logit\"])\n","\n","    seen_predictions = {}\n","    nbest = []\n","    for pred in prelim_predictions:\n","      if len(nbest) >= n_best_size:\n","        break\n","      feature = features[pred.feature_index]\n","      if pred.start_index > 0:  # this is a non-null prediction\n","        tok_tokens = feature.tokens[pred.start_index:(pred.end_index + 1)]\n","        orig_doc_start = feature.token_to_orig_map[pred.start_index]\n","        orig_doc_end = feature.token_to_orig_map[pred.end_index]\n","        orig_tokens = example.doc_tokens[orig_doc_start:(orig_doc_end + 1)]\n","        tok_text = \" \".join(tok_tokens)\n","\n","        # De-tokenize WordPieces that have been split off.\n","        tok_text = tok_text.replace(\" ##\", \"\")\n","        tok_text = tok_text.replace(\"##\", \"\")\n","\n","        # Clean whitespace\n","        tok_text = tok_text.strip()\n","        tok_text = \" \".join(tok_text.split())\n","        orig_text = \" \".join(orig_tokens)\n","\n","        final_text = get_final_text(tok_text, orig_text, do_lower_case)\n","        if final_text in seen_predictions:\n","          continue\n","\n","        seen_predictions[final_text] = True\n","      else:\n","        final_text = \"\"\n","        seen_predictions[final_text] = True\n","\n","      nbest.append(\n","          _NbestPrediction(\n","              text=final_text,\n","              start_logit=pred.start_logit,\n","              end_logit=pred.end_logit))\n","\n","    # In very rare edge cases we could have no valid predictions. So we\n","    # just create a nonce prediction in this case to avoid failure.\n","    if not nbest:\n","      nbest.append(\n","          _NbestPrediction(text=\"empty\", start_logit=0.0, end_logit=0.0))\n","\n","    assert len(nbest) >= 1\n","\n","    total_scores = []\n","    best_non_null_entry = None\n","    for entry in nbest:\n","      total_scores.append(entry.start_logit + entry.end_logit)\n","      if not best_non_null_entry:\n","        if entry.text:\n","          best_non_null_entry = entry\n","\n","    probs = _compute_softmax(total_scores)\n","\n","    nbest_json = []\n","    for (i, entry) in enumerate(nbest):\n","      output = collections.OrderedDict()\n","      output[\"text\"] = entry.text\n","      output[\"probability\"] = probs[i]\n","      output[\"start_logit\"] = entry.start_logit\n","      output[\"end_logit\"] = entry.end_logit\n","      nbest_json.append(output)\n","\n","    assert len(nbest_json) >= 1\n","\n","    all_predictions[example.qas_id] = nbest_json[0][\"text\"]\n","    all_nbest_json[example.qas_id] = nbest_json\n","\n","  with tf.gfile.GFile(output_prediction_file, \"w\") as writer:\n","    writer.write(json.dumps(all_predictions, indent=4) + \"\\n\")\n","\n","  with tf.gfile.GFile(output_nbest_file, \"w\") as writer:\n","    writer.write(json.dumps(all_nbest_json, indent=4) + \"\\n\")\n","\n","  if FLAGS.version_2_with_negative:\n","    with tf.gfile.GFile(output_null_log_odds_file, \"w\") as writer:\n","      writer.write(json.dumps(scores_diff_json, indent=4) + \"\\n\")"],"metadata":{"id":"EXmN-H1vKUZS","executionInfo":{"status":"ok","timestamp":1701616922831,"user_tz":-540,"elapsed":10,"user":{"displayName":"이태후","userId":"03468433647806446322"}}},"execution_count":28,"outputs":[]},{"cell_type":"code","source":["class FeatureWriter(object):\n","  \"\"\"Writes InputFeature to TF example file.\"\"\"\n","\n","  def __init__(self, filename, is_training):\n","    self.filename = filename\n","    self.is_training = is_training\n","    self.num_features = 0\n","    self._writer = tf.python_io.TFRecordWriter(filename)\n","\n","  def process_feature(self, feature):\n","    \"\"\"Write a InputFeature to the TFRecordWriter as a tf.train.Example.\"\"\"\n","    self.num_features += 1\n","\n","    def create_int_feature(values):\n","      feature = tf.train.Feature(\n","          int64_list=tf.train.Int64List(value=list(values)))\n","      return feature\n","\n","    features = collections.OrderedDict()\n","    features[\"unique_ids\"] = create_int_feature([feature.unique_id])\n","    features[\"input_ids\"] = create_int_feature(feature.input_ids)\n","    features[\"input_mask\"] = create_int_feature(feature.input_mask)\n","    features[\"segment_ids\"] = create_int_feature(feature.segment_ids)\n","\n","    if self.is_training:\n","      features[\"start_positions\"] = create_int_feature([feature.start_position])\n","      features[\"end_positions\"] = create_int_feature([feature.end_position])\n","      impossible = 0\n","      if feature.is_impossible:\n","        impossible = 1\n","      features[\"is_impossible\"] = create_int_feature([impossible])\n","\n","    tf_example = tf.train.Example(features=tf.train.Features(feature=features))\n","    self._writer.write(tf_example.SerializeToString())\n","\n","  def close(self):\n","    self._writer.close()"],"metadata":{"id":"_ATOlvjyLwmM","executionInfo":{"status":"ok","timestamp":1701616922831,"user_tz":-540,"elapsed":10,"user":{"displayName":"이태후","userId":"03468433647806446322"}}},"execution_count":29,"outputs":[]},{"cell_type":"code","source":["import random\n","import os\n","\n","def main(_):\n","\n","  tf.logging.set_verbosity(tf.logging.INFO)\n","  bert_config = BertConfig.from_json_file(FLAGS.bert_config_file)\n","\n","  tf.gfile.MakeDirs(FLAGS.output_dir)\n","\n","  tokenizer = FullTokenizer(\n","      vocab_file=FLAGS.vocab_file, do_lower_case=FLAGS.do_lower_case)\n","\n","  tpu_cluster_resolver = None\n","  is_per_host = tf.contrib.tpu.InputPipelineConfig.PER_HOST_V2\n","  run_config = tf.contrib.tpu.RunConfig(\n","      cluster=tpu_cluster_resolver,\n","      master=FLAGS.master,\n","      model_dir=FLAGS.output_dir,\n","      save_checkpoints_steps=FLAGS.save_checkpoints_steps,\n","      tpu_config=tf.contrib.tpu.TPUConfig(\n","          iterations_per_loop=FLAGS.iterations_per_loop,\n","          num_shards=FLAGS.num_tpu_cores,\n","          per_host_input_for_training=is_per_host))\n","\n","  train_examples = None\n","  num_train_steps = None\n","  num_warmup_steps = None\n","  if FLAGS.do_train:\n","    train_examples = read_squad_examples(\n","        input_file=FLAGS.train_file, is_training=True)\n","    num_train_steps = int(\n","        len(train_examples) / FLAGS.train_batch_size * FLAGS.num_train_epochs)\n","    num_warmup_steps = int(num_train_steps * FLAGS.warmup_proportion)\n","\n","    # Pre-shuffle the input to avoid having to make a very large shuffle\n","    # buffer in in the `input_fn`.\n","    rng = random.Random(12345)\n","    rng.shuffle(train_examples)\n","\n","  model_fn = model_fn_builder(\n","      bert_config=bert_config,\n","      init_checkpoint=FLAGS.init_checkpoint,\n","      learning_rate=FLAGS.learning_rate,\n","      num_train_steps=num_train_steps,\n","      num_warmup_steps=num_warmup_steps,\n","      use_one_hot_embeddings=False)\n","\n","  # If TPU is not available, this will fall back to normal Estimator on CPU\n","  # or GPU.\n","  estimator = tf.contrib.tpu.TPUEstimator(\n","      model_fn=model_fn,\n","      config=run_config,\n","      train_batch_size=FLAGS.train_batch_size,\n","      predict_batch_size=FLAGS.predict_batch_size)\n","\n","  if FLAGS.do_train:\n","    # We write to a temporary file to avoid storing very large constant tensors\n","    # in memory.\n","    train_writer = FeatureWriter(\n","        filename=os.path.join(FLAGS.output_dir, \"train.tf_record\"),\n","        is_training=True)\n","    convert_examples_to_features(\n","        examples=train_examples,\n","        tokenizer=tokenizer,\n","        max_seq_length=FLAGS.max_seq_length,\n","        doc_stride=FLAGS.doc_stride,\n","        max_query_length=FLAGS.max_query_length,\n","        is_training=True,\n","        output_fn=train_writer.process_feature)\n","    train_writer.close()\n","\n","    tf.logging.info(\"***** Running training *****\")\n","    tf.logging.info(\"  Num orig examples = %d\", len(train_examples))\n","    tf.logging.info(\"  Num split examples = %d\", train_writer.num_features)\n","    tf.logging.info(\"  Batch size = %d\", FLAGS.train_batch_size)\n","    tf.logging.info(\"  Num steps = %d\", num_train_steps)\n","    del train_examples\n","\n","    train_input_fn = input_fn_builder(\n","        input_file=train_writer.filename,\n","        seq_length=FLAGS.max_seq_length,\n","        is_training=True,\n","        drop_remainder=True)\n","    estimator.train(input_fn=train_input_fn, max_steps=num_train_steps)\n","\n","  if FLAGS.do_predict:\n","    eval_examples = read_squad_examples(\n","        input_file=FLAGS.predict_file, is_training=False)\n","\n","    eval_writer = FeatureWriter(\n","        filename=os.path.join(FLAGS.output_dir, \"eval.tf_record\"),\n","        is_training=False)\n","    eval_features = []\n","\n","    def append_feature(feature):\n","      eval_features.append(feature)\n","      eval_writer.process_feature(feature)\n","\n","    convert_examples_to_features(\n","        examples=eval_examples,\n","        tokenizer=tokenizer,\n","        max_seq_length=FLAGS.max_seq_length,\n","        doc_stride=FLAGS.doc_stride,\n","        max_query_length=FLAGS.max_query_length,\n","        is_training=False,\n","        output_fn=append_feature)\n","    eval_writer.close()\n","\n","    tf.logging.info(\"***** Running predictions *****\")\n","    tf.logging.info(\"  Num orig examples = %d\", len(eval_examples))\n","    tf.logging.info(\"  Num split examples = %d\", len(eval_features))\n","    tf.logging.info(\"  Batch size = %d\", FLAGS.predict_batch_size)\n","\n","    all_results = []\n","\n","    predict_input_fn = input_fn_builder(\n","        input_file=eval_writer.filename,\n","        seq_length=FLAGS.max_seq_length,\n","        is_training=False,\n","        drop_remainder=False)\n","\n","    # If running eval on the TPU, you will need to specify the number of\n","    # steps.\n","    all_results = []\n","    for result in estimator.predict(\n","        predict_input_fn, yield_single_examples=True):\n","      if len(all_results) % 1000 == 0:\n","        tf.logging.info(\"Processing example: %d\" % (len(all_results)))\n","      unique_id = int(result[\"unique_ids\"])\n","      start_logits = [float(x) for x in result[\"start_logits\"].flat]\n","      end_logits = [float(x) for x in result[\"end_logits\"].flat]\n","      all_results.append(\n","          RawResult(\n","              unique_id=unique_id,\n","              start_logits=start_logits,\n","              end_logits=end_logits))\n","\n","    output_prediction_file = os.path.join(FLAGS.output_dir, \"predictions.json\")\n","    output_nbest_file = os.path.join(FLAGS.output_dir, \"nbest_predictions.json\")\n","    output_null_log_odds_file = os.path.join(FLAGS.output_dir, \"null_odds.json\")\n","\n","    write_predictions(eval_examples, eval_features, all_results,\n","                      FLAGS.n_best_size, FLAGS.max_answer_length,\n","                      FLAGS.do_lower_case, output_prediction_file,\n","                      output_nbest_file, output_null_log_odds_file)\n"],"metadata":{"id":"rilBOADPL6iI","executionInfo":{"status":"ok","timestamp":1701616922831,"user_tz":-540,"elapsed":10,"user":{"displayName":"이태후","userId":"03468433647806446322"}}},"execution_count":30,"outputs":[]},{"cell_type":"code","source":["tf.compat.v1.app.run()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":364},"id":"Y35hIsDwQwPl","executionInfo":{"status":"error","timestamp":1701620202220,"user_tz":-540,"elapsed":673,"user":{"displayName":"이태후","userId":"03468433647806446322"}},"outputId":"e8f37b1e-04ba-44cf-cb9a-33d6b006dcc0"},"execution_count":40,"outputs":[{"output_type":"error","ename":"IllegalFlagValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mIllegalFlagValueError\u001b[0m                     Traceback (most recent call last)","\u001b[0;32m<ipython-input-40-1af1451780d5>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/platform/app.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(main, argv)\u001b[0m\n\u001b[1;32m     34\u001b[0m   \u001b[0mmain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmain\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_sys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'__main__'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m   \u001b[0m_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags_parser\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_parse_flags_tolerate_undef\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/absl/app.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(main, argv, flags_parser)\u001b[0m\n\u001b[1;32m    298\u001b[0m   \"\"\"\n\u001b[1;32m    299\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m     args = _run_init(\n\u001b[0m\u001b[1;32m    301\u001b[0m         \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margv\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0margv\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0margv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m         \u001b[0mflags_parser\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/absl/app.py\u001b[0m in \u001b[0;36m_run_init\u001b[0;34m(argv, flags_parser)\u001b[0m\n\u001b[1;32m    367\u001b[0m   \u001b[0;31m# Set up absl logging handler.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m   \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_absl_handler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 369\u001b[0;31m   args = _register_and_parse_flags_with_usage(\n\u001b[0m\u001b[1;32m    370\u001b[0m       \u001b[0margv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m       \u001b[0mflags_parser\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflags_parser\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/absl/app.py\u001b[0m in \u001b[0;36m_register_and_parse_flags_with_usage\u001b[0;34m(argv, flags_parser)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m   \u001b[0moriginal_argv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margv\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0margv\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0margv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m   \u001b[0margs_to_main\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mflags_parser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moriginal_argv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mFLAGS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_parsed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'FLAGS must be parsed after flags_parser is called.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/platform/app.py\u001b[0m in \u001b[0;36m_parse_flags_tolerate_undef\u001b[0;34m(argv)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_parse_flags_tolerate_undef\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m   \u001b[0;34m\"\"\"Parse args, returning any unknown flags (ABSL defaults to crashing).\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFLAGS\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_sys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margv\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0margv\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0margv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mknown_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/platform/flags.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'__wrapped'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/absl/flags/_flagvalues.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, argv, known_only)\u001b[0m\n\u001b[1;32m    654\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    655\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmark_as_parsed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 656\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate_all_flags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    657\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mprogram_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0munparsed_args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/absl/flags/_flagvalues.py\u001b[0m in \u001b[0;36mvalidate_all_flags\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    514\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mflag\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m       \u001b[0mall_validators\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflag\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidators\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_assert_validators\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_validators\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_assert_validators\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidators\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/absl/flags/_flagvalues.py\u001b[0m in \u001b[0;36m_assert_validators\u001b[0;34m(self, validators)\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0mmessages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%s: %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmessages\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0m_exceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIllegalFlagValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__delattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflag_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mIllegalFlagValueError\u001b[0m: flag --vocab_file=None: Flag --vocab_file must have a value other than None.\nflag --bert_config_file=None: Flag --bert_config_file must have a value other than None.\nflag --output_dir=None: Flag --output_dir must have a value other than None."]}]}]}